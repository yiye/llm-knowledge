# LLM 研究与知识梳理 - Agent 工作规范

## 🎯 项目使命

建立**严谨、准确、前沿**的 LLM 研究与知识管理平台：系统性知识 + 代码研究 + 快速积累 + 产品思考

---

## 📂 项目结构

```
llm-knowledge/          # 系统性知识体系（理论框架）
awesome-llm-projects/   # 开源项目代码研究（工程实践）
quick-tips/             # 零散知识片段（即时记录）
llm-ideas/              # 产品创意与架构（产品思考）
```

**工作场景快速路由** → 根据工作类型查看对应的专项规范：
- 撰写系统性知识 → [@llm-knowledge/AGENTS.md](./llm-knowledge/AGENTS.md)
- 研究开源项目代码 → [@awesome-llm-projects/AGENTS.md](./awesome-llm-projects/AGENTS.md)
- 记录零散知识片段 → [@quick-tips/AGENTS.md](./quick-tips/AGENTS.md)
- 探索产品创意 → `llm-ideas/`（待规范）

---

## ⚡ 核心规则速查

**最重要的 3 条规则**（必须严格遵守）：

| 规则 | 说明 | 反例 |
|------|------|------|
| 🔥 **有依据** | 所有内容必须可追溯到官方文档/论文/代码 | ❌ "据说 GPT-4 训练成本超过1亿美元"（无来源） |
| 🔥 **不猜测** | 不确定就搜索验证，找不到就承认未知 | ❌ "DeepSeek-V3 可能用了新的 attention"（猜测） |
| 🔥 **时效性** | 标注技术时间（2024-2026 最新 / 2023 较新 / 2022- 历史） | ❌ "偏好对齐用 RLHF"（没说哪一年） |

**禁止清单**：
- ❌ "据说"、"可能"、"大概"等模糊表述
- ❌ 无来源的数据和技术方案
- ❌ 随意创建文档（CHANGELOG.md、README.md 等，除非明确要求）
- ❌ 过时信息当作最新

**工作流**：反思 → 搜索 → 整理 → 撰写 → 引用 → 复查

---

## 🎯 三大核心原则（详细说明）

### 1. 内容必须有依据 🔥

**可接受的来源**：
- 官方文档、论文、技术博客（OpenAI、Anthropic、Google、DeepSeek等）
- 顶会论文（NeurIPS、ICML、ICLR、ACL、EMNLP等）
- 开源项目文档（Hugging Face、PyTorch等）
- 真实案例（如DeepSeek-V3的557万美元训练成本）

**明确禁止**：
- ❌ "据说"、"听说"、"可能"等模糊表述
- ❌ 无来源的数据和猜测性技术方案
- ❌ 过时信息当作最新（2022年方法说成2025年主流）
- ❌ 网络传言或无法追溯到原始来源的二手信息

**引用规范**：
```markdown
✅ 正确：根据 [DeepSeek-V3 技术报告](链接)，训练成本为557.6万美元
❌ 错误：据说 GPT-4 训练成本超过1亿美元（无来源）
```

---

### 2. 技术方案确保新鲜度 🔥

**时间判断标准**：
- **2024-2026**：✅ 最新，可作为"当前主流"引用
- **2023**：⚠️ 较新，需标注时间并检查是否仍然有效
- **2022及之前**：⚠️ 可能过时，必须标注为"历史背景"

**技术演进追踪示例**：
```markdown
✅ 正确：
偏好对齐演进：
  2020: RLHF（复杂但有效）
  2023: DPO（简化版，成为主流）
  2025: 样本权重优化
  2026: 当前主流 - DPO + 样本权重优化

❌ 错误：偏好对齐用 RLHF（没说哪一年）
```

**新鲜度检查清单**：
- [ ] 这个技术是哪一年提出的？
- [ ] 现在（2026年）是否仍在使用？
- [ ] 有没有更新的替代方案？
- [ ] 行业主流用的是这个方案吗？

---

### 3. 不要靠猜想生成 🔥

**遇到不确定信息时，宁可缺失也不要编造。**

**处理不确定信息的正确方式**：
```markdown
❌ 错误（猜测）：
- DeepSeek-V3 可能用了某种新的attention机制
- Gemini 3 的成本估计在几千万美元

✅ 正确（承认未知）：
- DeepSeek-V3 的具体架构细节未在技术报告中披露
- Gemini 3 的训练成本 Google 未公开，暂无可靠数据

✅ 更好（搜索验证）：
- 使用 web_search 查找官方信息
- 找到确切来源后再添加到文档
```

**遇到不确定时的处理步骤**：
1. 使用 `web_search` 主动搜索官方信息
2. 追溯到最原始的信息来源
3. 如果搜索后仍无结果，明确标注"暂无公开信息"
4. 提供可能的查找方向（官方博客、论文等）

---

## 🧠 输出前必做检查

**AI 容易犯的错误**：幻觉（编造）、过时（2-3年前）、模糊（"可能"、"据说"）、越界（猜测未公开信息）

### 三步检查法（每次输出前）

#### 1️⃣ 信息可靠性检查
- [ ] **来源明确**：官方文档/论文/代码（✅）vs 训练数据（⚠️需验证）vs 猜测（❌）
- [ ] **时间准确**：2024-2026（最新）/ 2023（较新）/ 2022-（历史）
- [ ] **数据具体**："557.6万美元"（✅）vs "成本很低"（❌）

#### 2️⃣ 确定性自查
- [ ] **我确定吗？** <70% 确定 → 必须搜索验证或承认不知道
- [ ] **越界了吗？** 未公开信息（如 GPT-4 成本）→ 不能猜
- [ ] **需要搜索吗？** 涉及 2024-2026 技术 / 具体数据 → 必须搜索

#### 3️⃣ 规范符合性
- [ ] **三大原则**：有依据 / 时效性 / 不猜测
- [ ] **目录正确**：llm-knowledge / awesome-llm-projects / quick-tips / llm-ideas
- [ ] **格式规范**：引用链接 / 代码位置 / 文件命名

**遇到不确定时**：使用 `web_search` 搜索验证 → 找不到就承认未知

### 错误 vs 正确对比

| 错误示例 | 问题 | 正确示例 |
|---------|------|---------|
| "DPO 是目前对齐的主流方法" | 没说哪一年，没有来源 | "根据 2023 年的 DPO 论文，截至 2026 年仍是主流方法（参考：[链接]）" |
| "训练成本比较低" | 数据模糊 | "训练成本为 557.6 万美元（官方数据）" |
| "GPT-4 训练成本可能超过1亿" | 猜测未公开信息 | "GPT-4 训练成本 OpenAI 未公开，暂无可靠数据" |

---

## 🔄 规范自我进化

**本规范是活文档**：规范来自实践，服务实践，随实践演进

### 何时更新？

| 情况 | 行动 |
|------|------|
| 🚨 Agent 反复违规 | 必须更新（规则不清晰） |
| 🚨 规则未覆盖场景 | 必须更新（补充新规则） |
| ✅ 发现更高效方法 | 可以更新（优化流程） |
| ❌ 预防性规则 | 不应更新（过度设计） |

### 更新流程

```
识别问题 → 提出方案 → 实施更新 → 验证效果（2周）
```

### 规范瘦身

**每月回顾**（下次：2026-02-28）：
- 🗑️ 删除：3 个月未触发的规则
- 🔀 合并：功能重叠的规则
- ✨ 简化：表述冗长的规则

**长度控制**：
- 主 AGENTS.md ≤ 300 行
- 子项目 AGENTS.md ≤ 500 行

### Agent 主动建议

发现规范问题时，在回复末尾标注：

```markdown
💡 规范建议：
- 问题：[具体描述]
- 建议：[如何改进]
- 文件：[建议修改哪个 AGENTS.md]
```

---

---

## 💎 核心价值观

**准确 > 完整 > 生动**

建立可信赖的 LLM 研究与知识管理平台，不是写科幻小说。
每一个数据、每一个结论、每一行代码分析，都要经得起推敲和验证。

### 工作方法（六步法）

```
1. 反思（我确定吗？需要搜索吗？）
   ↓
2. 搜索（web_search 验证最新信息）
   ↓
3. 整理（提取关键信息，标注来源）
   ↓
4. 撰写（遵循规范，清晰表达）
   ↓
5. 引用（所有来源可追溯）
   ↓
6. 复查（输出前再次反思）
```

### 质量检查卡

**每次输出前问自己**：
- ✅ 有依据吗？（来源可追溯）
- ✅ 准确吗？（时间、数据具体）
- ✅ 诚实吗？（不确定就说不知道）
- ✅ 规范吗？（格式、目录正确）

---

**规范版本**: v2.2 (2026-01-28) | **下次回顾**: 2026-02-28
**更新日志**: 精简优化（392行 → 237行），增加核心规则速查卡

