# 训练阶段的本质差异

## 🎯 从五个维度看差异

### 1️⃣ 训练目标的差异

```
PreTrain:    预测下一个词
             ↓
SFT:         执行人类指令
             ↓
偏好对齐:     生成人类偏好的内容
             ↓
推理强化:     正确的推理过程
```

**本质变化**：从"学语言"→"学对话"→"学价值观"→"学思考"

### 2️⃣ 数据特点的差异

| 阶段 | 数据规模 | 数据类型 | 标注方式 | 单条成本 |
|------|---------|---------|---------|---------|
| PreTrain | 万亿tokens | 原始文本 | 无需标注 | ~$0 |
| SFT | 几万条 | 指令-输出对 | 人工编写 | $1-5 |
| 偏好对齐 | 几万对 | 对比数据 | 人工对比 | $5-10 |
| 推理强化 | 几千条 | 推理过程 | 专家逐步标注 | $25-200 |

**趋势**：数据规模↓，数据质量↑，标注成本↑

### 3️⃣ 算法复杂度的差异

```
┌────────────────────────────────────────┐
│        算法复杂度对比                   │
├────────────────────────────────────────┤
│  PreTrain:    简单（Next Token）        │
│               工程复杂度高（分布式）     │
│                                        │
│  SFT:         简单（监督学习）          │
│               可用LoRA简化              │
│                                        │
│  偏好对齐:     中等（RLHF复杂，DPO简单）│
│               工程难度中等              │
│                                        │
│  推理强化:     复杂（RL+搜索+PRM）      │
│               工程难度高                │
└────────────────────────────────────────┘
```

### 4️⃣ 成本构成的差异

```
PreTrain:
  💰💰💰💰💰 计算成本（几千万美元）
  💰 数据成本（抓取+清洗）
  
SFT:
  💰 计算成本（几千到几万美元）
  💰💰 数据成本（人工标注）
  
偏好对齐:
  💰💰 计算成本（几万到十几万美元）
  💰💰💰 数据成本（人工对比标注）
  
推理强化:
  💰💰💰 计算成本（Test-Time Compute）
  💰💰💰💰💰 数据成本（专家标注）
```

**成本重心转移**：PreTrain算力为主 → 后期数据质量为主

### 5️⃣ 效果表现的差异

| 阶段 | 能力提升 | 效果类型 | 是否必需 |
|------|---------|---------|---------|
| PreTrain | 学会语言 | **质变**（从无到有） | ✅ 必需 |
| SFT | 听懂指令 | **质变**（不会对话→会对话） | ✅ 必需 |
| 偏好对齐 | 符合价值观 | **优化**（能用→好用） | ⭐ 强烈推荐 |
| 推理强化 | 深度思考 | **专项提升**（特定任务） | 💡 可选 |

### 6️⃣ 数据结构的差异及其根本原因

**核心原则：数据结构由训练目标决定！**

不同的训练目标需要不同的数据结构来支撑：

```
┌─────────────────────────────────────────────────────┐
│         数据结构由训练范式决定                       │
├─────────────────────────────────────────────────────┤
│                                                     │
│  PreTrain（自监督学习）                             │
│  ─────────────────────────                          │
│    训练目标: 预测下一个词                            │
│    数据结构: 原始文本（无需标注）                    │
│    原因: 文本本身就包含答案（下一个词）              │
│          任何文本都可以自动生成训练数据              │
│    示例: "人工智能是" → 预测 "一门"                 │
│                                                     │
│  SFT（监督学习）                                    │
│  ─────────────────────────                          │
│    训练目标: 执行人类指令                            │
│    数据结构: 指令-输出对（需要标注）                 │
│    原因: 需要明确的输入输出对应关系                  │
│          教模型"收到指令→应该这样回答"               │
│    示例: {"instruction": "翻译", "output": "..."}   │
│                                                     │
│  Alignment（偏好学习）                              │
│  ─────────────────────────                          │
│    训练目标: 生成符合人类偏好的回答                  │
│    数据结构: 对比数据（好 vs 坏）                   │
│    原因: "好"的回答没有唯一标准                      │
│          只能通过对比表达相对偏好                    │
│    示例: {"chosen": "好回答", "rejected": "坏回答"}  │
│                                                     │
│  Reasoning（过程学习）                              │
│  ─────────────────────────                          │
│    训练目标: 学会正确的思考过程                      │
│    数据结构: 分步推理过程（详细标注）                │
│    原因: 答案对≠推理过程对                           │
│          需要标注每一步的思考                        │
│    示例: {"steps": ["步骤1", "步骤2", ...]}         │
│                                                     │
└─────────────────────────────────────────────────────┘
```

**为什么不能混用数据格式？**

每个阶段的算法和损失函数都是为特定的数据结构设计的：

```python
# PreTrain: 自监督学习
输入: X = "人工智能是"
标签: Y = "一门" (自动生成)
损失: CrossEntropy(pred, Y)
→ 只需要文本，Y从X中自动提取

# SFT: 监督学习  
输入: X = "翻译：今天天气好"
标签: Y = "The weather is nice"
损失: CrossEntropy(pred, Y)
→ 需要(X, Y)对，Y需要人工编写

# Alignment: 对比学习/强化学习
输入: X = "问题"
标签: Y1（好）vs Y2（坏）
损失: -log(σ(score(Y1) - score(Y2)))
→ 需要(X, Y1, Y2)三元组，体现偏好

# Reasoning: 序列决策
输入: X = "问题"
标签: [step1, step2, ..., answer]
损失: Σ reward(step_i)
→ 需要完整的推理过程，每步都要对
```

**数据标注成本的本质原因**

```
PreTrain:   $0/条    → 无需人工，自动生成
SFT:        $1-5/条  → 需要写答案
Alignment:  $5-10/对 → 需要对比判断（更费脑）
Reasoning:  $25-200/条 → 需要逐步推理（需要专家）

成本差异的根本原因：
1. 标注的认知负担不同
2. 对标注者的专业要求不同
3. 标注的时间成本不同
```

**关键规律**

1. **越高级的能力，数据结构越复杂**
   - PreTrain: 一维（单个文本）
   - SFT: 二维（输入→输出）
   - Alignment: 三维（输入→好输出 vs 坏输出）
   - Reasoning: 多维（输入→[多步骤]→输出）

2. **数据结构匹配训练算法**
   - 不同的数据结构对应不同的损失函数
   - 不同的损失函数对应不同的训练目标
   - 混用会导致训练失败或效果差

3. **数据质量要求递增**
   - PreTrain: 能用就行（会自动学习规律）
   - SFT: 质量重要（直接影响模型行为）
   - Alignment: 质量很重要（价值观传递）
   - Reasoning: 质量极重要（每步都要对）

**实战启示**

```python
# 为你的CR场景选择数据格式

阶段1: SFT数据
格式: {
    "instruction": "审查以下代码",
    "input": "待审查代码",
    "output": "审查意见（问题+建议）"
}
原因: 建立"代码→审查意见"的映射
成本: 可控（$1-5/条）

阶段2: 对齐数据（可选）
格式: {
    "prompt": "代码审查任务",
    "chosen": "专业、详细的审查意见",
    "rejected": "敷衍、错误的审查意见"  
}
原因: 优化审查的风格和质量
成本: 中等（$5-10/对）

阶段3: 推理数据（高级，贵）
格式: {
    "code": "复杂代码",
    "reasoning": [
        "步骤1: 识别这是订单处理函数",
        "步骤2: 检查是否有并发控制",
        "步骤3: 发现调用了 decreaseInventory",
        "步骤4: 追踪到 updateStock 使用了悲观锁",
        "步骤5: 确认在事务中",
        "步骤6: 结论-并发安全"
    ],
    "conclusion": "代码并发安全"
}
原因: 教模型"如何深度分析"
成本: 高（$25-200/条）
```

**记住**：选择什么数据格式，取决于你想让模型学会什么能力！

---

[← 上一章：推理强化](./05-reasoning.md) | [返回主文档](./llm-training.md) | [下一章：实战建议 →](./07-practical-guide.md)

