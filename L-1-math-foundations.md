# 数学基础：理解 LLM 的数学语言

> ⬆️ 支撑**所有上层** - 概率论、线性代数、信息论基础

---

## 📚 目录

1. [概率论基础](#概率论基础)
2. [马尔科夫链](#马尔科夫链)
3. [线性代数核心](#线性代数核心)
   - [归一化](#归一化-normalization-)
4. [信息论基础](#信息论基础)
5. [与 LLM 的关系](#与-llm-的关系)

---

## 🎲 概率论基础

### 条件概率 P(B|A)

**定义**：在 A 发生的条件下，B 发生的概率

```
P(B|A) = P(A ∩ B) / P(A)

读作："A 发生时 B 的概率"
```

**直观例子**：

```
场景：抽卡游戏

总共 100 张卡：
  按稀有度：50 张普通 + 30 张稀有 + 20 张传说
  按颜色：  40 张蓝色 + 60 张非蓝色
  其中蓝色稀有卡：10 张

问题：抽到一张稀有卡，它是蓝色的概率？

A = 稀有卡，P(A) = 30/100 = 0.3
B = 蓝色，P(B) = 40/100 = 0.4
A ∩ B = 蓝色稀有卡，P(A ∩ B) = 10/100 = 0.1  ← 已知条件

P(蓝色 | 稀有卡) = P(A ∩ B) / P(A)
                  = 0.1 / 0.3
                  = 1/3  ← 33%
```

**与 LLM 的关系**：

```python
# LLM 的核心就是条件概率
P(next_token | context)

例子：
  输入："猫在___"
  
  P("睡觉" | "猫在") = 0.45
  P("玩耍" | "猫在") = 0.25
  P("吃饭" | "猫在") = 0.15
  ...
```

### 期望 E[X]

**定义**：随机变量的平均值（加权平均）

```
E[X] = Σ xᵢ × P(xᵢ)

离散情况：所有可能值 × 对应概率，求和
```

**直观例子**：

```
掷骰子游戏：
  掷到 1: 得 10 元，概率 1/6
  掷到 2: 得 20 元，概率 1/6
  掷到 3: 得 30 元，概率 1/6
  掷到 4: 得 40 元，概率 1/6
  掷到 5: 得 50 元，概率 1/6
  掷到 6: 得 60 元，概率 1/6

期望收益：
  E[收益] = 10×(1/6) + 20×(1/6) + ... + 60×(1/6)
          = (10+20+30+40+50+60) / 6
          = 210 / 6
          = 35 元

含义：长期玩下去，平均每次得 35 元
```

**与 LLM 的关系**：

```python
# DPO 的损失函数用到期望
L_DPO = -E[log σ(r(y_w) - r(y_l))]

含义：
  对所有训练数据求平均
  → 期望损失最小化
```

### 方差 Var(X)

**定义**：随机变量离平均值的平方差的期望

```
Var(X) = E[(X - E[X])²]
       = E[X²] - (E[X])²

含义：数据的离散程度
```

**直观例子**：

```
两个班级的成绩：

班级 A：[50, 50, 50, 50, 50]
  平均分 = 50
  方差 = 0  ← 所有人都一样

班级 B：[0, 25, 50, 75, 100]
  平均分 = 50
  方差 = 1000  ← 成绩差距大

→ 方差衡量"散布程度"
```

**与 LLM 的关系**：

```python
# Attention 中的 Scaled 点积
Score = Q·K / √d_k

为什么除以 √d_k？
  因为 Q·K 的方差 = d_k
  除以 √d_k 后，方差 = 1
  → 控制数值范围，防止 softmax 饱和
```

### 最大似然估计 (MLE)

**定义**：找到让观测数据出现概率最大的参数

```
给定数据 D = {x₁, x₂, ..., xₙ}
找参数 θ，使得 P(D | θ) 最大

L(θ) = P(D | θ) = ∏ᵢ P(xᵢ | θ)  ← 似然函数
```

**直观例子**：

```
问题：一个硬币，抛 10 次，7 次正面，3 次反面
     求正面概率 p？

似然函数：
  L(p) = C(10,7) × p⁷ × (1-p)³

求最大值：
  dL/dp = 0
  → p = 7/10 = 0.7

含义：让观测数据（7正3反）概率最大的 p 是 0.7
```

**与 LLM 的关系**：

```python
# LLM 的训练目标：最大似然
Loss = -log P(y | x)  ← 负对数似然

训练数据："猫在睡觉"
  最大化 P("猫") × P("在"|"猫") × P("睡觉"|"猫在")
  等价于 最小化 -log P(...)
  
→ 找参数 θ，让训练数据出现概率最大
→ 这就是 PreTrain 的本质
```

---

## 🔗 马尔科夫链

### 核心定义

**马尔科夫性质（无记忆性）**：

```
未来状态只依赖于当前状态，与过去历史无关

P(Xₜ₊₁ | Xₜ, Xₜ₋₁, ..., X₀) = P(Xₜ₊₁ | Xₜ)
```

### 通俗理解

```
天气预测游戏：
  今天晴天 → 明天 70% 晴天，30% 雨天
  今天雨天 → 明天 40% 晴天，60% 雨天

马尔科夫性质：
  ✅ 只看今天天气，预测明天
  ❌ 不需要看"昨天、前天、大前天..."
  
假设违反：
  "如果连续 3 天晴天，第 4 天可能下雨"
  → 这就不是马尔科夫链了（需要看历史）
```

### 关键要素

```
1. 状态空间
   S = {晴天, 雨天, 阴天}
   
2. 转移概率
   P(明天=晴 | 今天=晴) = 0.7
   P(明天=雨 | 今天=晴) = 0.2
   P(明天=阴 | 今天=晴) = 0.1
   
3. 转移矩阵
          晴天  雨天  阴天
   晴天 [ 0.7   0.2   0.1 ]
   雨天 [ 0.4   0.4   0.2 ]
   阴天 [ 0.3   0.3   0.4 ]
   
4. 初始状态
   今天是晴天
```

### 与 LLM 的关系

**LLM 不是严格的马尔科夫模型**：

```
严格马尔科夫：
  P(wordₜ | wordₜ₋₁)  ← 只看前一个词

N-gram 模型（接近马尔科夫）：
  P(wordₜ | wordₜ₋₁, wordₜ₋₂, wordₜ₋₃)  ← 看前 N 个词

Transformer（LLM）：
  P(wordₜ | word₁, word₂, ..., wordₜ₋₁)  ← 看全部历史
  
  → 不是马尔科夫！
  → 通过 Attention 看到全部上下文
```

**但理解马尔科夫链仍然有用**：

```
1. 历史背景
   早期语言模型（N-gram）就是马尔科夫链
   
2. 生成过程
   LLM 的自回归生成类似"增强版马尔科夫过程"
   
3. 概念基础
   P(wordₜ | context) 的思想源于马尔科夫链
```

---

## 📏 线性代数核心

### 向量

**定义**：一维数组

```python
v = [1, 2, 3]  ← 3维向量
```

**几何意义**：空间中的一个点或方向

```
2D 向量：
  v = [3, 4]
  
  ●───────→
  (3, 4)
```

**与 LLM 的关系**：

```
词向量：
  猫 = [0.2, -0.5, 0.8, ..., 0.4]  (768维)
  
隐藏状态：
  h = [0.1, 0.3, -0.2, ..., 0.6]  (768维)
```

### 向量的模（长度）

**定义**：

```
|v| = √(v₁² + v₂² + ... + vₙ²)
```

**例子**：

```
v = [3, 4]
|v| = √(3² + 4²)
    = √(9 + 16)
    = √25
    = 5
```

**与 LLM 的关系**：

```python
# 1. 余弦相似度的分母
cos(A, B) = A·B / (|A| × |B|)

# 向量模用于归一化，消除长度影响，只看方向
# 详见 L-2: 点积与相似度

# 2. RMSNorm（当前 LLM 主流归一化）
RMS(x) = √(Σxᵢ² / n)  ← 本质是"平均模长"

# LLaMA、Qwen 等主流模型使用 RMSNorm
# 比 LayerNorm 更简洁高效

# 3. 梯度裁剪（防止梯度爆炸）
if |∇L| > max_norm:
    ∇L = ∇L × (max_norm / |∇L|)  ← 用模来控制梯度大小
```

### 矩阵

**定义**：二维数组

```python
A = [[1, 2, 3],
     [4, 5, 6]]  ← 2×3 矩阵
```

**与 LLM 的关系**：

```
权重矩阵：
  W = [768, 768]  ← Attention 的投影矩阵
  
批量词向量：
  X = [batch_size, seq_len, 768]
```

### 矩阵乘法

**定义**：

```
C = A × B

Cᵢⱼ = Σₖ Aᵢₖ × Bₖⱼ
```

**例子**：

```
A = [[1, 2],    B = [[5, 6],
     [3, 4]]         [7, 8]]

C = [[1×5+2×7,  1×6+2×8],
     [3×5+4×7,  3×6+4×8]]
     
  = [[19, 22],
     [43, 50]]
```

**与 LLM 的关系**：

```python
# 线性层
output = X @ W + b

# Attention
scores = Q @ K.T  ← 矩阵乘法
output = attention @ V  ← 矩阵乘法
```

### 转置

**定义**：行列互换

```
A = [[1, 2, 3],    A^T = [[1, 4],
     [4, 5, 6]]            [2, 5],
                           [3, 6]]
```

**与 LLM 的关系**：

```python
# Attention 中的转置
scores = Q @ K.T  ← K 的转置

K = [batch, seq_k, d]
K.T = [batch, d, seq_k]  ← 转置后

Q @ K.T = [batch, seq_q, d] @ [batch, d, seq_k]
        = [batch, seq_q, seq_k]  ← 得到相似度矩阵
```

**为什么 K 需要转置？**

```
Q = (n, d)  ← n 个 query，每个 d 维
K = (n, d)  ← n 个 key，每个 d 维

目标：计算每个 query 和每个 key 的点积 → (n, n) 矩阵

Q × K   = (n, d) × (n, d) = ❌ 维度不匹配（d ≠ n）
Q × K.T = (n, d) × (d, n) = (n, n) ✅ 可以相乘

转置让 K 的行变成列，使得 Q 的每一行能与 K 的每一行做点积
→ 矩阵乘法 = 批量点积

详见 [L-2: 点积与相似度](./L-2-dot-product-similarity.md#11-为什么-k-需要转置)
```

### 非线性变换与激活函数 🔥

**问题：为什么线性变换不够？**

```
线性变换：y = Wx + b

特点：直线！

  y
  │      /
  │    /
  │  /
  │/
  └──────── x

无论 W、b 怎么变，都是直线
```

**关键洞察：线性变换的叠加 = 还是线性**

```
问题：两层线性变换等于什么？

  y = W2 × (W1 × x)
    = (W2 × W1) × x
    = W3 × x          ← 还是线性！

无论叠多少层：
  W5 × W4 × W3 × W2 × W1 × x = W_合并 × x
  
→ 100 层线性 = 1 层线性，白堆了！
→ 深度神经网络没有意义
```

**解决：加入非线性变换（激活函数）**

```
非线性变换：让函数能"拐弯"

例如 ReLU: y = max(0, x)

  y
  │      /
  │    /
  │  /
  │───      ← 这里有个拐点！
  └──────── x
    负数变0，正数不变

加入非线性后：
  y = W2 × ReLU(W1 × x)
  
  这个无法合并成 W × x
  因为中间有个"拐弯"（ReLU）打断了

→ 每一层都有意义！
→ 层数越多，能拟合的函数越复杂
```

**形象类比**：

```
线性变换 = 只能画直线
非线性变换 = 可以画曲线

任务：用线条画一只猫

  只用直线（线性）：
    ╱╲
    ─┴─    ← 只能画个大概轮廓

  可以用曲线（非线性）：
    /\_/\
   ( o.o )  ← 能画出圆润的细节
    > ^ <

神经网络要拟合复杂的函数（语言、图像...）
必须能"画曲线"，所以需要非线性！
```

**常见激活函数**：

```
┌──────────────┬─────────────────────┬──────────────────────┐
│ 激活函数     │ 公式                │ 使用场景             │
├──────────────┼─────────────────────┼──────────────────────┤
│ ReLU         │ max(0, x)           │ 经典，简单高效       │
├──────────────┼─────────────────────┼──────────────────────┤
│ GELU         │ x × Φ(x)            │ GPT、BERT 系列       │
├──────────────┼─────────────────────┼──────────────────────┤
│ SiLU/Swish   │ x × σ(x)            │ LLaMA 系列           │
├──────────────┼─────────────────────┼──────────────────────┤
│ SwiGLU       │ Swish(xW) ⊙ (xV)   │ 当前主流（2024-2025）│
└──────────────┴─────────────────────┴──────────────────────┘

Φ(x) = 标准正态分布的累积分布函数
σ(x) = sigmoid = 1/(1+e^(-x))
⊙ = 逐元素乘法
```

**与 LLM 的关系**：

```python
# FFN（前馈神经网络）中的激活函数
class FFN(nn.Module):
    def forward(self, x):
        h = self.w1(x)      # 线性：升维
        h = F.gelu(h)       # 非线性：激活函数 ← 关键！
        y = self.w2(h)      # 线性：降维
        return y

# 没有激活函数会怎样？
# h = self.w2(self.w1(x))
# = x @ (W1 @ W2)
# = x @ W3  ← 等于一层，FFN 就废了
```

**一句话总结**：

```
非线性变换 = 让神经网络能学习复杂模式的关键
没有它：无论多少层都等于一层（线性叠加）
有了它：层数越深，表达能力越强
```

### 归一化 (Normalization) 🔥

**定义**：将数据调整到特定范围或分布的过程

```
归一化的本质：
  让数据"标准化"，消除不必要的差异
  
类比：
  不同国家的成绩满分不同：
    美国：100 分制
    法国：20 分制
    日本：5 分制
  
  直接比较 90 vs 18 vs 4.5？不公平！
  归一化后：90% vs 90% vs 90% → 公平比较 ✅
```

#### 为什么需要归一化？

**原因 1：消除长度/尺度影响**

```
问题：向量长度可能带有"噪声"

词向量例子：
  "the"  出现 100 万次 → 向量长度可能很大
  "cat"  出现 1 万次   → 向量长度较小

但语义上：
  "cat" 和 "dog" 应该相似（都是动物）
  不应该因为 "the" 出现多就说它和什么都相似！

归一化后：
  所有向量长度 = 1，只比较方向（语义）
  → 公平比较 ✅
```

**原因 2：数值稳定性**

```
问题：数值太大或太小会出问题

太大（梯度爆炸）：
  值 = [1000, 2000, 3000]
  经过几层后 → [10⁹, 10¹⁰, ...]  ← 溢出！

太小（梯度消失）：
  值 = [0.0001, 0.0002, 0.0003]
  经过几层后 → [10⁻²⁰, ...]  ← 精度丢失！

归一化后：
  值保持在合理范围（如均值0、方差1）
  → 训练稳定 ✅
```

**原因 3：加速训练收敛**

```
未归一化：
  不同特征尺度差异大
  梯度方向"歪斜"
  → 需要更多步才能收敛

归一化后：
  所有特征在相似尺度
  梯度方向更"正"
  → 收敛更快 ✅
```

**原因 4：让比较在同一尺度**

```
未归一化：
  向量 A 的值在 [-100, 100]
  向量 B 的值在 [-0.01, 0.01]
  
  A·B 的结果难以解释

归一化后（如 L2 归一化）：
  |A| = |B| = 1
  A·B 在 [-1, 1]，就是余弦相似度
  → 直观可解释 ✅
```

#### 常见归一化类型

```
┌────────────────┬─────────────────────────┬──────────────────────────┐
│ 类型           │ 公式                    │ 使用场景                 │
├────────────────┼─────────────────────────┼──────────────────────────┤
│ L2 归一化      │ x / |x|                 │ 向量检索、余弦相似度     │
│                │ 让长度=1                │                          │
├────────────────┼─────────────────────────┼──────────────────────────┤
│ Min-Max 归一化 │ (x - min) / (max - min) │ 映射到 [0, 1]            │
│                │                         │ 图像像素、特征缩放       │
├────────────────┼─────────────────────────┼──────────────────────────┤
│ Z-Score 标准化 │ (x - μ) / σ             │ 统计分析                 │
│                │ 均值=0，方差=1          │ 传统机器学习             │
├────────────────┼─────────────────────────┼──────────────────────────┤
│ BatchNorm      │ 对 batch 维度归一化     │ CNN、早期模型            │
│                │                         │ 依赖 batch 大小          │
├────────────────┼─────────────────────────┼──────────────────────────┤
│ LayerNorm      │ 对特征维度归一化        │ Transformer（2017-2023） │
│                │ 每个样本独立            │ BERT、GPT-2/3            │
├────────────────┼─────────────────────────┼──────────────────────────┤
│ RMSNorm ⭐     │ x / RMS(x)              │ 当前主流（2024-）        │
│                │ RMS = √(Σx²/n)          │ LLaMA、Qwen、DeepSeek    │
└────────────────┴─────────────────────────┴──────────────────────────┘
```

#### LayerNorm vs RMSNorm

```python
# LayerNorm（传统）
def layer_norm(x):
    mean = x.mean()           # 计算均值
    std = x.std()             # 计算标准差
    return (x - mean) / std   # 减均值，除标准差

# RMSNorm（当前主流，更简洁）
def rms_norm(x):
    rms = sqrt(mean(x ** 2))  # 只计算 RMS
    return x / rms            # 不减均值，只除 RMS

# RMSNorm 的优势：
#   ✅ 计算量更小（省去均值计算）
#   ✅ 效果相当
#   ✅ LLaMA、Qwen、DeepSeek 等都用 RMSNorm
```

#### 归一化在 Transformer 中的位置

```
Transformer 层：

  输入
    ↓
  ┌─────────────────────┐
  │  Multi-Head         │
  │  Attention          │
  └─────────────────────┘
    ↓
  (+) ← 残差连接
    ↓
  ┌─────────────────────┐
  │  LayerNorm/RMSNorm  │  ← 归一化 ⭐
  └─────────────────────┘
    ↓
  ┌─────────────────────┐
  │  Feed-Forward       │
  │  Network            │
  └─────────────────────┘
    ↓
  (+) ← 残差连接
    ↓
  ┌─────────────────────┐
  │  LayerNorm/RMSNorm  │  ← 归一化 ⭐
  └─────────────────────┘
    ↓
  输出
  
每层都有归一化，保证训练稳定！
```

#### 与 LLM 的关系

```python
# 1. Attention 中的 Scaled（一种归一化）
scores = Q @ K.T / sqrt(d_k)  # 除以 √d_k 控制方差

# 2. 每个 Transformer 层都有 Norm
class TransformerLayer:
    def forward(self, x):
        # Attention + 残差 + 归一化
        x = x + self.attention(self.norm1(x))
        # FFN + 残差 + 归一化  
        x = x + self.ffn(self.norm2(x))
        return x

# 3. 向量检索用 L2 归一化
query_norm = query / np.linalg.norm(query)
# 归一化后点积 = 余弦相似度
```

#### 什么场景不需要归一化？

并非所有场景都需要归一化：

```
┌─────────────────────────┬──────────────┬───────────────────────┐
│ 场景                    │ 需要归一化？ │ 原因                  │
├─────────────────────────┼──────────────┼───────────────────────┤
│ 神经网络中间层          │ ✅ 需要      │ 稳定训练              │
│ 向量检索/余弦相似度     │ ✅ 需要      │ 消除长度影响          │
│ 梯度下降优化            │ ✅ 需要      │ 加速收敛              │
├─────────────────────────┼──────────────┼───────────────────────┤
│ 决策树/随机森林         │ ❌ 不需要    │ 基于排序，不受尺度影响│
│ 数据已在合理范围        │ ❌ 不需要    │ 天然归一化            │
│ 长度信息有意义          │ ❌ 不需要    │ 归一化会丢失信息      │
│ 已有其他归一化机制      │ ❌ 不需要    │ 避免重复              │
│ 回归任务输出层          │ ❌ 不需要    │ 保留真实尺度          │
└─────────────────────────┴──────────────┴───────────────────────┘
```

**不需要归一化的典型场景**：

**场景 1：树模型（决策树、随机森林、XGBoost）**

```python
# 树模型基于"分割点"，不受尺度影响

# 数据：预测是否买房
data = {
    "年龄": [25, 35, 45, 55],      # 范围 20-60
    "收入": [50000, 80000, 120000, 200000],  # 范围 5万-20万
    "买房": [0, 0, 1, 1]
}

# 决策树的逻辑：
#   if 收入 > 100000:
#       买房 = 1
#   else:
#       买房 = 0

# 无论收入单位是"元"还是"万元"：
#   100000 元 vs 10 万元 → 分割逻辑相同！
#   树模型只关心"大于/小于"，不关心具体数值大小

# → 不需要归一化 ✅
```

**场景 2：数据本身已在合理范围**

```python
# 例子 1：概率值
probs = [0.1, 0.3, 0.6]  # 已经在 [0, 1]，天然归一化

# 例子 2：One-hot 编码
cat_one_hot = [1, 0, 0]  # 已经是 0 或 1
dog_one_hot = [0, 1, 0]

# 例子 3：图像像素（常见处理）
pixel = 128
pixel_normalized = pixel / 255  # = 0.502，已经在 [0, 1]

# 例子 4：Softmax 输出
logits = [2.0, 1.0, 0.5]
softmax_output = [0.59, 0.24, 0.17]  # 已经在 [0, 1] 且和=1

# → 这些数据本身就在合理范围，不需要额外归一化 ✅
```

**场景 3：长度信息本身有意义**

```python
# Attention 中的例子

# 假设模型学到：向量长度 = "重要程度"
query_normal = [1.0, 0.0]      # 普通查询
query_important = [10.0, 0.0]  # 重要查询（长度大 10 倍）

key = [1.0, 0.0]

# 用点积：
score_normal = 1.0 * 1.0 = 1.0
score_important = 10.0 * 1.0 = 10.0  # 重要查询得分更高！

# 用余弦相似度（归一化）：
cos_normal = 1.0      # 方向相同
cos_important = 1.0   # 方向也相同，长度信息丢失了！

# → 如果长度携带"重要性"信息，归一化会丢失它 ❌

# 类似场景：
#   - 推荐系统：用户向量长度 ≈ 活跃度
#   - 搜索排序：文档向量长度 ≈ 相关性强度
```

**场景 4：已有其他机制处理**

```python
# Transformer 中的例子

class TransformerAttention:
    def forward(self, x):
        # 1. LayerNorm 已经控制了分布
        x = self.layer_norm(x)  # 均值≈0，方差≈1
        
        Q = x @ W_Q
        K = x @ W_K
        
        # 2. Scaled 已经控制了方差
        scores = Q @ K.T / sqrt(d_k)  # 除以 √d_k
        
        # → 已经有两层归一化机制了
        # → 不需要再用余弦相似度（显式长度归一化）
        
        # 如果再归一化：
        # scores = cosine(Q, K)  ← 多余！反而可能丢失有用信息
        
        return softmax(scores) @ V

# → 避免重复归一化 ✅
```

**场景 5：回归任务输出层**

```python
# 例子：预测房价

# 训练数据
X = [[100, 3], [150, 4], [200, 5]]  # 面积、房间数
y = [500000, 800000, 1200000]        # 真实房价（元）

# 模型结构
class HousePriceModel:
    def forward(self, x):
        # 中间层：可以用归一化
        h = self.layer1(x)
        h = self.layer_norm(h)  # ✅ 中间层归一化
        h = self.layer2(h)
        
        # 输出层：不能归一化！
        output = self.output_layer(h)
        # output 应该是 500000，不是 0.5
        
        return output  # 保留真实尺度

# 类似场景：
#   - 预测温度：输出 25°C，不是 0.25
#   - 预测销量：输出 10000 件，不是 0.01
#   - 预测时长：输出 120 分钟，不是 0.12

# → 输出层保留真实尺度，方便解释和使用 ✅
```

**判断标准**：

```
✅ 尺度差异会影响结果 → 需要归一化
❌ 尺度差异不影响 or 长度有意义 → 不需要归一化
```

**一句话总结**：

```
归一化 = 让数据保持合理范围，消除尺度干扰

没有它：训练不稳定，梯度爆炸/消失
有了它：训练稳定，收敛更快

LLM 中的归一化：
  ✅ LayerNorm/RMSNorm：每层都用，稳定训练
  ✅ Scaled Dot-Product：控制 Attention 方差
  ✅ L2 归一化：向量检索，点积=余弦
  
什么时候不需要：
  ❌ 树模型：不受尺度影响
  ❌ 长度有意义：归一化会丢失信息
  ❌ 已有其他机制：避免重复归一化
```

---

## 📊 信息论基础

### 交叉熵 (Cross Entropy)

**定义**：衡量两个概率分布的差异

```
H(P, Q) = -Σ P(x) log Q(x)

P: 真实分布
Q: 预测分布
```

**直观例子**：

```
真实答案："猫"
  P = [0, 1, 0, 0]  ← one-hot
      |  |  |  |
     猫 狗 鸟 鱼

模型预测：
  Q = [0.1, 0.6, 0.2, 0.1]
  
交叉熵：
  H(P, Q) = -[0×log(0.1) + 1×log(0.6) + 0×log(0.2) + 0×log(0.1)]
          = -log(0.6)
          ≈ 0.51
          
含义：
  模型给正确答案的概率越高，交叉熵越小
  Q("猫") = 0.6 → H ≈ 0.51
  Q("猫") = 0.9 → H ≈ 0.11  ← 更好
```

**与 LLM 的关系**：

```python
# LLM 的训练损失
Loss = CrossEntropy(y_true, y_pred)
     = -log P(正确词 | context)

训练目标：最小化交叉熵
→ 最大化正确词的概率
```

### KL 散度 (KL Divergence)

**定义**：衡量两个概率分布的"距离"

```
KL(P || Q) = Σ P(x) log(P(x) / Q(x))
           = Σ P(x) [log P(x) - log Q(x)]

性质：
  - KL(P || Q) ≥ 0
  - KL(P || P) = 0
  - KL(P || Q) ≠ KL(Q || P)  ← 不对称
```

**直观理解**：

```
P: 真实分布
Q: 近似分布

KL(P || Q) 衡量：
  用 Q 近似 P 的信息损失

例子：
  P = [0.5, 0.5]  ← 均匀分布
  Q = [0.9, 0.1]  ← 偏向分布
  
  KL(P || Q) = 0.5×log(0.5/0.9) + 0.5×log(0.5/0.1)
             ≈ 0.51  ← 损失较大
```

**与 LLM 的关系**：

```python
# DPO 训练中的 KL 约束
Objective = E[reward] - β × KL(π || π_ref)

含义：
  最大化奖励
  但不要偏离参考模型 π_ref 太远
  
  KL(π || π_ref) 越小 → π 越接近 π_ref
  β 控制约束强度
```

### 熵 (Entropy)

**定义**：分布的不确定性

```
H(P) = -Σ P(x) log P(x)

熵越大 → 不确定性越高
```

**例子**：

```
均匀分布（最不确定）：
  P = [0.25, 0.25, 0.25, 0.25]
  H = -4 × 0.25 × log(0.25) = 2 bits  ← 最大熵

确定分布（最确定）：
  P = [1, 0, 0, 0]
  H = -1 × log(1) = 0 bits  ← 最小熵
```

**与 LLM 的关系**：

```
温度采样：
  logits / temperature
  
  temperature = 1.0 → 原始分布
  temperature > 1.0 → 熵增大（更随机）
  temperature < 1.0 → 熵减小（更确定）
```

---

## 🔗 与 LLM 的关系

### 1. 概率论在 LLM 中的应用

```
核心公式：
  P(next_token | context)  ← 条件概率

训练目标：
  最大化 E[log P(y | x)]  ← 期望

损失函数：
  CrossEntropy(y_true, y_pred)  ← 交叉熵

对齐约束：
  KL(π || π_ref) < δ  ← KL 散度
```

### 2. 线性代数在 LLM 中的应用

```
词向量：
  v = [768维向量]

权重矩阵：
  W_Q, W_K, W_V, W_O

Attention 计算：
  scores = Q @ K.T  ← 矩阵乘法
  output = softmax(scores) @ V

所有计算都是向量和矩阵运算
```

### 3. 信息论在 LLM 中的应用

```
PreTrain：
  Loss = CrossEntropy(y, ŷ)

DPO：
  Loss = -E[log σ(...)] - β × KL(π || π_ref)

采样：
  temperature 控制熵
  top-k, top-p 控制分布
```

### 4. 数学概念的层级关系

```
概率论（底层）
  ↓ 定义
条件概率 P(y|x)
  ↓ 应用
LLM 的核心：P(next_token | context)
  ↓ 优化
交叉熵损失
  ↓ 约束
KL 散度
  ↓ 实现
DPO 训练
```

---

## 🎯 核心要点总结

### 1. 概率论

```
✅ 条件概率：P(B|A) - LLM 的核心
✅ 期望：E[X] - 损失函数的平均
✅ 方差：Var(X) - Scaled 点积的原因
✅ 最大似然：MLE - 训练的本质
```

### 2. 马尔科夫链

```
✅ 无记忆性：未来只依赖现在
✅ LLM 不是马尔科夫：看全部历史
✅ 但概念相关：自回归生成
```

### 3. 线性代数

```
✅ 向量：词向量、隐藏状态
✅ 矩阵：权重、批量数据
✅ 矩阵乘法：Attention 的核心运算
✅ 转置：K.T 在 Attention 中的作用
✅ 非线性变换：让深层网络有意义
✅ 归一化：LayerNorm/RMSNorm 稳定训练
```

### 4. 信息论

```
✅ 交叉熵：训练损失
✅ KL 散度：DPO 的约束
✅ 熵：采样的随机性控制
```

### 5. 学习建议

```
✅ 按需查阅：不必全部记住
✅ 理解概念：知道是什么、为什么
✅ 看到应用：在 LLM 中如何使用
✅ 回溯查询：遇到不懂的公式再回来看
```

---

## 📚 推荐阅读

**教材推荐**：
- 《概率论与数理统计》- 盛骤
- 《线性代数及其应用》- Gilbert Strang
- 《信息论基础》- Thomas Cover

**相关文档**：
- ⬆️ [L0: LLM 模型本质](./L0-llm-model-essence.md) - 看数学如何应用
- ➡️ [L-2: 点积与相似度](./L-2-dot-product-similarity.md) - 线性代数的具体应用
- ➡️ [L-3: 表示学习基础](./L-3-representation-learning.md) - 向量的应用

---

**记住**：数学是工具，不是目的。

理解概念 > 记住公式。看到应用 > 纸上推导。✨

---

*最后更新：2026年1月*
