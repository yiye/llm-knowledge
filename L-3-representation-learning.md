# 表示学习基础：为什么 LLM 需要词向量？

> ⬆️ 支撑 **L0（LLM 模型本质）** - 理解 Embedding 层为什么这样设计

---

## 📚 目录

1. [为什么需要词向量](#为什么需要词向量)
2. [词向量的学习过程](#词向量的学习过程)
3. [词向量的神奇特性](#词向量的神奇特性)
4. [分布式表示的本质](#分布式表示的本质)
5. [与 LLM 的关系](#与-llm-的关系)

---

## 🎯 为什么需要词向量？

### 核心问题：计算机不认识文字

```
人类：看到"猫"就知道是一种动物 ✅
计算机：看到"猫"只是一个字符串 ❌

如何让计算机"理解"文字？
→ 需要把文字变成数字！
```

### 三种方案的对比

#### ❌ 方案 1：简单编号

```python
词表 = {"猫": 1, "狗": 2, "鸟": 3, "苹果": 4, "香蕉": 5}

编号后：
  "猫" → 1
  "狗" → 2
  "苹果" → 4
```

**问题**：

```
1. 暗示了顺序关系
   → "狗"(2) 比"猫"(1) 大？没道理

2. 距离没有语义意义
   → "猫"(1) 和 "狗"(2) 的距离 = 1
   → "猫"(1) 和 "苹果"(4) 的距离 = 3
   → 但实际上猫和狗更相似！

3. 无法表示语义
   → 模型不知道"猫"和"狗"都是动物
```

#### ❌ 方案 2：One-Hot 编码

```python
词表大小 = 50000（假设）

猫 = [1, 0, 0, 0, ..., 0]  ← 第1位是1，其余49999位是0
狗 = [0, 1, 0, 0, ..., 0]  ← 第2位是1，其余49999位是0
鸟 = [0, 0, 1, 0, ..., 0]  ← 第3位是1
```

**问题**：

```
1. 维度爆炸
   → 50000 个词 = 50000 维向量
   → 太稀疏，计算和存储都很浪费

2. 所有词等距
   → 任意两个词的距离都是 √2
   → "猫"和"狗"的距离 = "猫"和"苹果"的距离
   → 无法表示语义相似度

3. 无法泛化
   → 见过"猫在睡觉"，没见过"狗在睡觉"
   → 模型不知道"狗"和"猫"类似
```

#### ✅ 方案 3：词向量（Dense Embedding）

```python
维度 = 768（固定）

猫 = [0.2, -0.5, 0.8, 0.1, -0.3, ..., 0.4]  ← 768个浮点数
狗 = [0.3, -0.4, 0.7, 0.2, -0.2, ..., 0.5]  ← 768个浮点数
鸟 = [0.1, -0.3, 0.6, 0.3, -0.1, ..., 0.3]  ← 768个浮点数

苹果 = [-0.5, 0.8, -0.2, 0.6, 0.4, ..., -0.1]  ← 768个浮点数
```

**优势**：

```
1. 密集表示
   → 只需 768 维，不管词表多大
   → 计算高效，存储节省

2. 语义相似度
   → similarity(猫, 狗) = 0.85  ← 相似度高
   → similarity(猫, 苹果) = 0.12  ← 相似度低
   → 反映了真实的语义关系

3. 泛化能力
   → 见过"猫在睡觉"
   → 猫和狗的向量相似
   → 模型自动推断"狗在睡觉"也合理 ✅
```

### 可视化对比

```
One-Hot 向量空间（50000维）：
  每个词是一个点
  所有词等距分布
  没有聚类结构
  
  猫 ●
  
      狗 ●
  
          苹果 ●


词向量空间（768维，降维到2D可视化）：
  相似词聚在一起
  语义关系清晰
  
        动物区域
      ┌─────────┐
      │  猫 ●   │
      │     狗 ● │
      │  鸟 ●   │
      └─────────┘
      
                  水果区域
                ┌─────────┐
                │ 苹果 ●   │
                │    香蕉 ● │
                └─────────┘
```

**与 LLM 的关系**：
- ✅ LLM 的 Embedding 层就是把词转为词向量
- ✅ 所有后续计算都基于词向量
- ✅ 词向量质量直接影响模型性能

---

## 🔧 词向量的学习过程

### 核心思想：分布式假设

```
"You shall know a word by the company it keeps"
（观其友，知其人）

一个词的意思 = 它经常出现在什么上下文中

例子：
  训练数据中经常出现：
    "猫在睡觉"
    "猫在玩耍"
    "狗在睡觉"
    "狗在玩耍"
  
  → 猫和狗出现在相似上下文
  → 它们的向量应该相似
```

### Word2Vec 算法（2013）⭐

**两种训练方法**：

#### 1. CBOW（连续词袋模型）

```
任务：用上下文预测中心词

输入："猫在___"
目标：预测"睡觉"

训练过程：
  1. "猫"和"在"的向量求平均
  2. 通过神经网络预测中心词
  3. 预测正确 → 向量不变
  4. 预测错误 → 调整向量

数百万次训练后：
  → 出现在相似上下文的词，向量会靠近
```

#### 2. Skip-gram

```
任务：用中心词预测上下文

输入："睡觉"
目标：预测"猫"、"在"

训练过程：
  1. "睡觉"的向量作为输入
  2. 预测周围的词
  3. 调整向量，让预测更准确
```

### 可视化：训练过程

```
初始状态（随机初始化）：
  猫 = [0.01, -0.02, 0.03, ...]  ← 随机
  狗 = [-0.01, 0.03, -0.02, ...] ← 随机
  苹果 = [0.02, 0.01, -0.01, ...] ← 随机
  
  → 向量之间没有关系


训练数据：
  "猫和狗都是宠物"
  "猫在睡觉"
  "狗在玩耍"
  "苹果很好吃"
  ...


训练中（逐渐调整）：
  见到"猫和狗都是宠物"
  → 猫和狗应该相似
  → 调整向量，让它们更接近
  
  见到"苹果很好吃"
  → 苹果和猫/狗不同
  → 保持距离


训练后（收敛）：
  猫 = [0.3, -0.4, 0.7, ...]
  狗 = [0.3, -0.4, 0.7, ...]  ← 和猫很接近
  苹果 = [-0.5, 0.8, -0.2, ...] ← 和猫/狗距离远

  similarity(猫, 狗) = 0.85 ✅
  similarity(猫, 苹果) = 0.12 ✅
```

### 现代 LLM 的方法：端到端学习

```
Word2Vec（2013）：
  ├─ 单独训练词向量
  └─ 然后用于下游任务

现代 LLM（Transformer）：
  ├─ 词向量和模型一起训练
  ├─ 词向量是模型的一部分（Embedding 层）
  └─ 端到端优化（End-to-End）

优势：
  ✅ 词向量针对具体任务优化
  ✅ 不需要单独训练
  ✅ 质量更高
```

### 训练目标

```python
# Word2Vec 的损失函数（Skip-gram）
Loss = -log P(上下文 | 中心词)

# LLM 的损失函数（预训练）
Loss = -log P(next_token | context)

本质相同：
  都在学习词的分布
  都让相似词的向量接近
```

**与 LLM 的关系**：
- ✅ LLM 的 PreTrain 阶段同时学习词向量
- ✅ 词向量是模型参数的一部分
- ✅ 训练数据越多，词向量质量越高

---

## ✨ 词向量的神奇特性

### 1. 语义相似度

```python
# 相似度计算（余弦相似度）
similarity(A, B) = cos(θ) = (A·B) / (|A|×|B|)

实际例子：
  similarity(猫, 狗) = 0.85    ← 都是动物
  similarity(猫, 小猫) = 0.92   ← 同一类
  similarity(猫, 老虎) = 0.68   ← 都是猫科
  similarity(猫, 苹果) = 0.12   ← 完全不相关
```

**注意：余弦相似度 vs 点积** ⭐

```
场景不同，选择不同：

┌─────────────────────┬──────────────┬─────────────────────────┐
│ 场景                │ 使用方法     │ 原因                    │
├─────────────────────┼──────────────┼─────────────────────────┤
│ 词向量检索/比较     │ 余弦相似度   │ 消除长度影响，公平比较  │
│ Attention 机制      │ 点积         │ 效率高，已有 LayerNorm  │
└─────────────────────┴──────────────┴─────────────────────────┘

为什么词向量比较用余弦？
  词向量长度受词频影响（高频词向量可能更长）
  → 余弦相似度只看方向，忽略长度
  → 公平比较语义相似度

为什么 Attention 用点积？
  → Q、K 已经过 LayerNorm 归一化
  → 点积计算快 2-3 倍
  → 长度信息可能有用（不想丢弃）

详见 [L-2: 点积与相似度 - 为什么不用余弦相似度](./L-2-dot-product-similarity.md#为什么不用余弦相似度)
```

**可视化**（降维到 2D）：

```
      动物
    ┌──────┐
    │ 猫●  │
    │  狗● │
    │ 鸟●  │
    └──────┘
    
          植物
        ┌──────┐
        │ 树●  │
        │  花● │
        └──────┘
        
              水果
            ┌──────┐
            │ 苹果● │
            │  香蕉●│
            └──────┘
```

### 2. 向量算术 ⭐⭐⭐

**惊人发现**：词向量支持算术运算！

```python
# 性别关系
vector(国王) - vector(男人) + vector(女人) ≈ vector(王后)

# 地理关系
vector(巴黎) - vector(法国) + vector(中国) ≈ vector(北京)

# 时态关系
vector(走) - vector(走的过去式walked) + vector(游泳swim) ≈ vector(游泳的过去式swam)

# 程度关系
vector(好) + [增强向量] ≈ vector(很好)
vector(大) + [增强向量] ≈ vector(巨大)
```

**为什么会这样？**

```
"国王" = 男性 + 皇室 + 权力 + ...
"男人" = 男性 + 普通 + ...
"女人" = 女性 + 普通 + ...

国王 - 男人 = 皇室 + 权力
(国王 - 男人) + 女人 = 女性 + 皇室 + 权力 = 王后 ✅

→ 向量的不同维度编码了不同的语义特征
→ 通过加减运算可以操作这些特征
```

### 3. 聚类现象

```
同类词自动聚在一起：

颜色词：
  红色、蓝色、绿色、黄色... 聚成一团

数字词：
  一、二、三、四、五... 聚成一团

动词：
  跑、跳、走、飞、游... 聚成一团

名词：
  猫、狗、鸟、鱼... 聚成一团

→ 模型自动发现了词的类别
→ 没有人告诉它什么是颜色、数字
→ 从数据中自动学到
```

### 4. 多义词的表示

```
问题：一个词有多个意思怎么办？

例子："银行"
  - 金融机构：去银行取钱
  - 河岸：河银行边散步

传统词向量（Word2Vec）：
  "银行" = 固定向量
  → 所有意思混在一起 ❌

现代词向量（Transformer）：
  "银行" = 根据上下文动态计算
  
  "去银行取钱"：
    → Attention 关注"取钱"
    → 向量偏向"金融机构"
  
  "河银行边散步"：
    → Attention 关注"河"
    → 向量偏向"河岸"
  
  → 同一个词，不同上下文，不同向量 ✅
```

**与 LLM 的关系**：
- ✅ LLM 的 Attention 机制解决了多义词问题
- ✅ 词向量不是静态的，而是动态生成的
- ✅ 这就是 Transformer 比 Word2Vec 强的原因

---

## 🧠 分布式表示的本质

### 什么是分布式表示？

```
局部表示（Localist Representation）❌：
  每个维度表示一个明确的特征
  
  维度1 = 是否是动物（0或1）
  维度2 = 颜色（1=黑，2=白，3=橙...）
  维度3 = 大小（1=小，2=中，3=大）
  
  猫 = [1, 3, 2]  ← 动物，橙色，中等大小


分布式表示（Distributed Representation）✅：
  一个特征分散在多个维度
  一个维度参与编码多个特征
  
  猫 = [0.2, -0.5, 0.8, 0.1, -0.3, ..., 0.4]  (768维)
  
  "是动物"这个特征：
    = 0.3×维度1 + 0.5×维度5 + 0.2×维度12 + ...
    （分散在多个维度）
  
  维度1 同时参与编码：
    ├─ "是动物"（30%）
    ├─ "能移动"（20%）
    ├─ "有生命"（15%）
    └─ 其他未知（35%）
```

### 为什么大部分维度无法解释？

```
问题：768 个维度都代表什么？

残酷的真相：
  ❌ 不知道！
  ❌ 无法为每个维度指定明确含义
  ❌ 维度是高度纠缠的（Entangled）

但这不是问题：
  ✅ 整体表现优异就够了
  ✅ 不需要理解每个维度
  ✅ 这就是深度学习的黑盒特性
```

### 维度纠缠的可视化

```
假设只有 3 个维度（方便理解）：

猫   = [0.8,  0.6, 0.2]
狗   = [0.7,  0.5, 0.3]
鸟   = [0.6,  0.4, 0.8]
苹果 = [-0.5, 0.8, 0.1]

维度1 可能编码了：
  ├─ 是否是动物（猫/狗/鸟都是正值）
  ├─ 是否常见（猫/狗是正值，鸟稍小）
  └─ 其他未知...

维度2 可能编码了：
  ├─ 大小（狗>猫>鸟）
  ├─ 温顺程度
  └─ 其他未知...

维度3 可能编码了：
  ├─ 能否飞（鸟最高）
  ├─ 活动方式
  └─ 其他未知...

→ 每个维度都是多个概念的混合
→ 无法明确解释
→ 但整体工作良好
```

### 分布式表示的优势

```
1. 表达能力强 ⭐
   768 维可以表示 2^768 种模式
   → 几乎无限的表达空间

2. 泛化能力强 ⭐
   见过"猫在睡觉"
   没见过"兔子在跳跃"
   → 但"兔子"和"猫"在某些维度相似
   → 模型能推断"兔子在跳跃"也合理

3. 鲁棒性强 ⭐
   某些维度损坏（噪声、量化）
   → 其他维度仍能恢复信息
   → 整体性能不会崩溃

4. 组合性强 ⭐
   可以通过向量加减创造新概念
   → king - man + woman = queen
```

### 类比：人脑的神经表示

```
人脑：
  ├─ 有 860 亿个神经元
  ├─ 每个神经元连接数千个其他神经元
  ├─ 一个概念分布在数百万个神经元
  └─ 无法指出"猫"的概念在哪个神经元

词向量：
  ├─ 有 768 个维度
  ├─ 每个维度参与多个概念
  ├─ 一个概念分布在多个维度
  └─ 无法指出"猫"的概念在哪个维度

→ 分布式表示类似人脑的工作方式
→ 这也许是智能的本质
```

**与 LLM 的关系**：
- ✅ LLM 的所有表示都是分布式的
- ✅ 不只是词向量，所有隐藏层都是
- ✅ 这让 LLM 能够处理极其复杂的语义

---

## 🔗 与 LLM 的关系

### 1. Embedding 层的作用

```
LLM 的第一步：

输入文本："猫在睡觉"
         ↓ Tokenization（分词）
Token序列：["猫", "在", "睡觉"]
         ↓ Embedding 层
词向量序列：
  [
    [0.2, -0.5, 0.8, ..., 0.4],   ← 猫
    [0.1, 0.3, -0.2, ..., 0.6],   ← 在
    [0.5, -0.1, 0.6, ..., 0.3]    ← 睡觉
  ]
         ↓ 后续 Transformer 层
  ...
```

### 2. 词向量的维度选择

```
常见模型的维度：

BERT-base:    768 维
BERT-large:   1024 维
GPT-2:        768 维
GPT-3:        12288 维  ← 巨大！
Llama 3:      4096 维

为什么 GPT-3 用 12288 维？
  ├─ 模型越大，维度越大
  ├─ 更强的表达能力
  └─ 能编码更复杂的语义

但也有成本：
  ├─ 计算量：O(d²)
  ├─ 显存占用
  └─ 训练时间
```

### 3. 词向量在训练中的演变

```
PreTrain 阶段：
  初始：随机向量
  训练中：学习语言规律
  训练后：编码语法、语义、知识

SFT 阶段：
  继续微调词向量
  → 适应指令格式
  → 强化任务相关的语义

DPO 阶段：
  继续微调词向量
  → 调整到人类偏好的方向
  → 提升生成质量

→ 词向量不是固定的，会随训练不断优化
```

### 4. 为什么向量维度不能太低或太高？

```
太低（如 50 维）：
  ❌ 表达能力不足
  ❌ 词义区分度低
  ❌ 模型性能差

适中（如 768 维）：
  ✅ 表达能力足够
  ✅ 计算效率高
  ✅ 性价比最佳

太高（如 10000 维）：
  ❌ 计算量暴增（O(d²)）
  ❌ 过拟合风险高
  ❌ 收益递减（性能提升不明显）

工程权衡：
  BERT 用 768 维是经验最佳值
  GPT-3 用 12288 维是因为模型巨大，需要匹配
```

---

## 🎯 核心要点总结

### 1. 为什么需要词向量？

```
✅ 计算机只认识数字，不认识文字
✅ 需要把文字变成向量（密集表示）
✅ 词向量能编码语义相似度
✅ 这是 LLM 理解语言的第一步
```

### 2. 词向量如何学习？

```
✅ 分布式假设：上下文相似 → 词义相似
✅ Word2Vec：用上下文预测词（2013，历史）
✅ Transformer：端到端学习（现代主流）
✅ 训练数据越多，词向量质量越高
```

### 3. 词向量的神奇特性

```
✅ 语义相似度：similarity(猫, 狗) = 0.85
✅ 向量算术：king - man + woman ≈ queen
✅ 自动聚类：同类词聚在一起
✅ 多义词：Transformer 动态生成向量
```

### 4. 分布式表示的智慧

```
✅ 一个特征分散在多个维度
✅ 一个维度编码多个特征
✅ 大部分维度无法解释，但整体优异
✅ 类似人脑的表示方式
```

### 5. 与 LLM 的关系

```
✅ Embedding 层：文本 → 词向量
✅ 维度选择：768（常见）到 12288（GPT-3）
✅ 训练演进：随 PreTrain/SFT/DPO 不断优化
✅ 词向量质量直接影响模型性能
```

---

## 📚 推荐阅读

**经典论文**：
- [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/abs/1301.3781) (Word2Vec, 2013)
- [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf) (2014)

**相关文档**：
- ⬆️ [L0: LLM 模型本质](./L0-llm-model-essence.md) - 理解 Embedding 层在模型中的位置
- ⬇️ [L-1: 数学基础](./L-1-math-foundations.md) - 向量、概率论基础
- ⬇️ [L-2: 点积与相似度](./L-2-dot-product-similarity.md) - 如何计算词向量的相似度

---

**记住**：词向量是 LLM 理解语言的第一步，也是最关键的一步。

没有好的词向量，后面的 Attention、FFN 都无法发挥作用。✨

---

*最后更新：2026年1月*
