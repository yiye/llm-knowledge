# 12 - è®­ç»ƒåŸºç¡€è®¾æ–½è®¾è®¡ï¼šGPUé›†ç¾¤ã€å­˜å‚¨ã€ç›‘æ§ä½“ç³»

> ğŸ¯ **æ ¸å¿ƒè§‚ç‚¹**ï¼šè®­ç»ƒåŸºç¡€è®¾æ–½æ˜¯LLMå·¥ç¨‹çš„åŸºçŸ³ã€‚æœ¬æ–‡æ·±å…¥è®²è§£GPUé›†ç¾¤æ¶æ„è®¾è®¡ã€Kubernetes + GPU Operatoré…ç½®ã€SLURMä½œä¸šè°ƒåº¦ã€é«˜æ€§èƒ½å­˜å‚¨ï¼ˆLustre/GPFSï¼‰ã€RDMA/InfiniBandç½‘ç»œä¼˜åŒ–ã€æˆæœ¬ä¼˜åŒ–ç­–ç•¥ï¼ˆSpotå®ä¾‹/æ··åˆäº‘ï¼‰ã€Prometheus/Grafanaç›‘æ§ä½“ç³»ï¼Œä»¥åŠæ•…éšœè¯Šæ–­ä¸å®¹é‡è§„åˆ’çš„å®æˆ˜ç»éªŒã€‚

---

## ğŸ“‹ ç›®å½•

1. [è®­ç»ƒåŸºç¡€è®¾æ–½å…¨æ™¯å›¾](#infrastructure-overview)
2. [GPUé›†ç¾¤æ¶æ„è®¾è®¡](#gpu-cluster-architecture)
3. [Kubernetes + GPU Operator](#kubernetes-gpu)
4. [SLURMä½œä¸šè°ƒåº¦ç³»ç»Ÿ](#slurm-scheduling)
5. [é«˜æ€§èƒ½å­˜å‚¨ï¼šLustre vs GPFS](#high-performance-storage)
6. [ç½‘ç»œä¼˜åŒ–ï¼šRDMA & InfiniBand](#network-optimization)
7. [èµ„æºè°ƒåº¦ç­–ç•¥](#resource-scheduling)
8. [æˆæœ¬ä¼˜åŒ–ï¼šSpotå®ä¾‹ä¸æ··åˆäº‘](#cost-optimization)
9. [ç›‘æ§ä½“ç³»ï¼šDCGM + Prometheus + Grafana](#monitoring-system)
10. [æ•…éšœè¯Šæ–­ä¸æ¢å¤](#fault-diagnosis)
11. [å®¹é‡è§„åˆ’ä¸æ‰©å±•](#capacity-planning)
12. [å®Œæ•´åŸºç¡€è®¾æ–½éƒ¨ç½²æ¡ˆä¾‹](#deployment-case)

---

<a name="infrastructure-overview"></a>
## ğŸ—ï¸ 1. è®­ç»ƒåŸºç¡€è®¾æ–½å…¨æ™¯å›¾

### 1.1 å®Œæ•´æ¶æ„å›¾

```python
"""
LLMè®­ç»ƒåŸºç¡€è®¾æ–½å…¨æ™¯
"""

class TrainingInfrastructureArchitecture:
    """
    è®­ç»ƒåŸºç¡€è®¾æ–½åˆ†å±‚æ¶æ„
    """
    
    def print_architecture(self):
        """
        æ‰“å°åŸºç¡€è®¾æ–½æ¶æ„å›¾
        """
        print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    LLMè®­ç»ƒåŸºç¡€è®¾æ–½æ¶æ„ï¼ˆ2025ï¼‰                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 5: å¼€å‘è€…ç•Œé¢                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Jupyter  â”‚  â”‚ VS Code  â”‚  â”‚   CLI    â”‚  â”‚  Web UI  â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 4: ä½œä¸šè°ƒåº¦å±‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚      SLURM         â”‚   OR   â”‚    Kubernetes      â”‚               â”‚
â”‚  â”‚  (HPCä¼ ç»Ÿæ–¹æ¡ˆ)     â”‚        â”‚  (äº‘åŸç”Ÿæ–¹æ¡ˆ)      â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: ç¼–æ’ä¸èµ„æºç®¡ç†                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ GPU      â”‚  â”‚ Network  â”‚  â”‚ Storage  â”‚  â”‚ Monitor  â”‚             â”‚
â”‚  â”‚ Operator â”‚  â”‚ Operator â”‚  â”‚  CSI     â”‚  â”‚  Agent   â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: ç½‘ç»œä¸å­˜å‚¨                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  InfiniBand/RDMA   â”‚        â”‚   Lustre/GPFS      â”‚               â”‚
â”‚  â”‚  (400Gb/s)         â”‚        â”‚   (PBçº§å­˜å‚¨)       â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: è®¡ç®—èµ„æºå±‚                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚ Node 1   â”‚  â”‚ Node 2   â”‚  â”‚ Node 3   â”‚  â”‚ Node N   â”‚             â”‚
â”‚  â”‚ 8xH100   â”‚  â”‚ 8xH100   â”‚  â”‚ 8xH100   â”‚  â”‚ 8xH100   â”‚             â”‚
â”‚  â”‚ 640GB    â”‚  â”‚ 640GB    â”‚  â”‚ 640GB    â”‚  â”‚ 640GB    â”‚             â”‚
â”‚  â”‚ NVLink   â”‚  â”‚ NVLink   â”‚  â”‚ NVLink   â”‚  â”‚ NVLink   â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """)

arch = TrainingInfrastructureArchitecture()
arch.print_architecture()
```

---

### 1.2 æŠ€æœ¯æ ˆé€‰å‹

```python
"""
2025å¹´è®­ç»ƒåŸºç¡€è®¾æ–½æŠ€æœ¯æ ˆå¯¹æ¯”
"""

tech_stack_comparison = {
    'ç»„ä»¶': ['ä½œä¸šè°ƒåº¦', 'å®¹å™¨ç¼–æ’', 'GPUç®¡ç†', 'ç½‘ç»œ', 'å­˜å‚¨', 'ç›‘æ§'],
    
    'HPCæ–¹æ¡ˆ (ä¼ ç»Ÿ)': [
        'SLURM',
        'æ— ï¼ˆç›´æ¥SSHï¼‰',
        'CUDAæ‰‹åŠ¨å®‰è£…',
        'InfiniBand',
        'Lustre',
        'Ganglia/Nagios'
    ],
    
    'K8sæ–¹æ¡ˆ (äº‘åŸç”Ÿ)': [
        'Kueue/Volcano',
        'Kubernetes',
        'GPU Operator',
        'RDMA/Multus',
        'CSI (Lustre/EBS)',
        'Prometheus/Grafana'
    ],
    
    'æ··åˆæ–¹æ¡ˆ (æ¨è)': [
        'SLURM + K8s',
        'K8s (æœåŠ¡)',
        'GPU Operator',
        'InfiniBand + RDMA',
        'Lustre',
        'Prometheus + DCGM'
    ]
}

import pandas as pd
df = pd.DataFrame(tech_stack_comparison).set_index('ç»„ä»¶')
print("æŠ€æœ¯æ ˆå¯¹æ¯”:")
print(df.to_string())

print("\nğŸ”¥ 2025æ¨èï¼šK8s + SLURMæ··åˆæ¶æ„")
print("  - K8sç®¡ç†æœåŠ¡ï¼ˆæ¨ç†ã€Webï¼‰")
print("  - SLURMç®¡ç†è®­ç»ƒä½œä¸šï¼ˆæ›´æˆç†Ÿï¼‰")
```

---

<a name="gpu-cluster-architecture"></a>
## ğŸ–¥ï¸ 2. GPUé›†ç¾¤æ¶æ„è®¾è®¡

### 2.1 GPUç¡¬ä»¶é€‰å‹ï¼ˆ2025ï¼‰

```python
"""
2025å¹´GPUé€‰å‹æŒ‡å—
"""

class GPUSelectionGuide:
    """
    GPUé€‰å‹åˆ†æ
    """
    
    def __init__(self):
        # 2025å¹´ä¸»æµè®­ç»ƒGPU
        self.gpus = {
            'NVIDIA H100 SXM5': {
                'memory': '80GB HBM3',
                'bandwidth': '3.35 TB/s',
                'compute_fp16': '989 TFLOPS',
                'compute_fp8': '1979 TFLOPS',
                'nvlink': '900 GB/s',
                'price_per_hour': 5.00,
                'use_case': 'ğŸ”¥ å¤§è§„æ¨¡è®­ç»ƒé¦–é€‰'
            },
            
            'NVIDIA H200': {
                'memory': '141GB HBM3e',
                'bandwidth': '4.8 TB/s',
                'compute_fp16': '989 TFLOPS',
                'compute_fp8': '1979 TFLOPS',
                'nvlink': '900 GB/s',
                'price_per_hour': 7.00,
                'use_case': 'ğŸ”¥ è¶…å¤§æ¨¡å‹/é•¿ä¸Šä¸‹æ–‡'
            },
            
            'NVIDIA A100 80GB': {
                'memory': '80GB HBM2e',
                'bandwidth': '2.0 TB/s',
                'compute_fp16': '312 TFLOPS',
                'compute_tf32': '156 TFLOPS',
                'nvlink': '600 GB/s',
                'price_per_hour': 3.50,
                'use_case': 'å¹³è¡¡æ€§ä»·æ¯”'
            },
            
            'NVIDIA L40S': {
                'memory': '48GB GDDR6',
                'bandwidth': '864 GB/s',
                'compute_fp16': '362 TFLOPS',
                'compute_fp8': '733 TFLOPS',
                'nvlink': 'æ— ',
                'price_per_hour': 2.00,
                'use_case': 'æ¨ç†+è½»é‡è®­ç»ƒ'
            },
            
            'Consumer RTX 4090': {
                'memory': '24GB GDDR6X',
                'bandwidth': '1008 GB/s',
                'compute_fp16': '82.6 TFLOPS',
                'nvlink': 'æ— ',
                'price': '$1,599 (ä¸€æ¬¡æ€§)',
                'use_case': 'ä¸ªäººç ”ç©¶/å°æ¨¡å‹'
            }
        }
    
    def recommend_gpu(self, model_size, budget, use_case):
        """
        æ ¹æ®éœ€æ±‚æ¨èGPU
        """
        print(f"\néœ€æ±‚åˆ†æ:")
        print(f"  æ¨¡å‹è§„æ¨¡: {model_size}")
        print(f"  é¢„ç®—: {budget}")
        print(f"  ç”¨é€”: {use_case}")
        print(f"\næ¨èæ–¹æ¡ˆ:")
        
        if model_size == '175B+':
            print(f"  ğŸ”¥ NVIDIA H200 (141GBæ˜¾å­˜)")
            print(f"     ç†ç”±: è¶…å¤§æ¨¡å‹éœ€è¦è¶…å¤§æ˜¾å­˜")
        
        elif model_size == '70B':
            if budget == 'high':
                print(f"  ğŸ”¥ NVIDIA H100 (80GB)")
                print(f"     ç†ç”±: æœ€å¿«è®­ç»ƒé€Ÿåº¦")
            else:
                print(f"  ğŸ”¥ NVIDIA A100 80GB")
                print(f"     ç†ç”±: æ€§ä»·æ¯”é«˜")
        
        elif model_size == '7B-13B':
            if budget == 'low':
                print(f"  ğŸ”¥ NVIDIA L40S æˆ– RTX 4090")
                print(f"     ç†ç”±: è¶³å¤Ÿè®­ç»ƒï¼Œæˆæœ¬æœ€ä½")
            else:
                print(f"  ğŸ”¥ NVIDIA A100 40GB")
                print(f"     ç†ç”±: è®­ç»ƒæ•ˆç‡é«˜")
        
        else:  # < 7B
            print(f"  ğŸ”¥ RTX 4090 æˆ– A6000")
            print(f"     ç†ç”±: æ¶ˆè´¹çº§å¡å¤Ÿç”¨")
    
    def calculate_cluster_config(self, target_model='70B', target_days=7):
        """
        è®¡ç®—é›†ç¾¤é…ç½®
        """
        # è®­ç»ƒ70Bæ¨¡å‹çš„ä¼°ç®—
        # å‚è€ƒDeepSeek-V3: 2.8M GPU hours for 671B model
        
        if target_model == '70B':
            # ä¼°ç®—ï¼š70Bçº¦éœ€200K GPU-hours
            gpu_hours_needed = 200_000
        elif target_model == '7B':
            gpu_hours_needed = 1_000
        else:
            gpu_hours_needed = 500_000  # 175B+
        
        # è®¡ç®—æ‰€éœ€GPUæ•°
        hours_in_period = target_days * 24
        num_gpus_needed = int(np.ceil(gpu_hours_needed / hours_in_period))
        
        # 8å¡æœåŠ¡å™¨
        num_nodes = int(np.ceil(num_gpus_needed / 8))
        
        print(f"\né›†ç¾¤é…ç½®è®¡ç®— ({target_model}æ¨¡å‹ï¼Œ{target_days}å¤©è®­ç»ƒ):")
        print("="*70)
        print(f"  æ€»GPU-hours: {gpu_hours_needed:,}")
        print(f"  è®­ç»ƒæ—¶é•¿: {target_days}å¤© = {hours_in_period}å°æ—¶")
        print(f"  æ‰€éœ€GPUæ•°: {num_gpus_needed}")
        print(f"  æ‰€éœ€èŠ‚ç‚¹æ•°: {num_nodes} (8å¡/èŠ‚ç‚¹)")
        print(f"  æ¨èGPU: H100 80GB")
        
        # æˆæœ¬ä¼°ç®—
        cost_per_gpu_hour = 5.00  # H100ä»·æ ¼
        total_cost = gpu_hours_needed * cost_per_gpu_hour
        
        print(f"\næˆæœ¬ä¼°ç®—:")
        print(f"  GPUæˆæœ¬: ${total_cost:,}")
        print(f"  å­˜å‚¨æˆæœ¬: ~${num_nodes * 100:,} (Lustre)")
        print(f"  ç½‘ç»œæˆæœ¬: ~${num_nodes * 50:,} (InfiniBand)")
        print(f"  æ€»è®¡: ~${total_cost + num_nodes * 150:,}")

guide = GPUSelectionGuide()
guide.recommend_gpu(model_size='70B', budget='medium', use_case='è®­ç»ƒ')
guide.calculate_cluster_config(target_model='70B', target_days=7)
```

---

### 2.2 GPUæœåŠ¡å™¨é…ç½®

```python
"""
æ ‡å‡†GPUè®­ç»ƒèŠ‚ç‚¹é…ç½®
"""

class GPUNodeConfiguration:
    """
    GPUèŠ‚ç‚¹é…ç½®è§„æ ¼
    """
    
    def dgx_h100_spec(self):
        """
        NVIDIA DGX H100é…ç½®ï¼ˆä¼ä¸šçº§ï¼‰
        """
        return {
            'GPU': '8x H100 SXM5 80GB',
            'GPUäº’è”': 'NVLink 4 (900 GB/såŒå‘)',
            'CPU': '2x Intel Xeon Platinum 8480C (56æ ¸)',
            'å†…å­˜': '2TB DDR5',
            'ç½‘ç»œ': '8x 200Gb/s InfiniBand',
            'å­˜å‚¨': '30TB NVMe (8x 3.84TB)',
            'ç”µæº': '10.2 kW',
            'ä»·æ ¼': '~$250,000',
            'TCO_3å¹´': '~$450,000 (å«ç”µè´¹ã€ç»´æŠ¤)'
        }
    
    def custom_8gpu_server(self):
        """
        è‡ªå»º8å¡æœåŠ¡å™¨é…ç½®ï¼ˆæ€§ä»·æ¯”ï¼‰
        """
        return {
            'GPU': '8x RTX 4090 24GB',
            'GPUäº’è”': 'PCIe 4.0 (64 GB/sï¼Œé€šè¿‡CPU)',
            'CPU': 'AMD Threadripper PRO 5995WX (64æ ¸)',
            'å†…å­˜': '512GB DDR4',
            'ç½‘ç»œ': '2x 100Gb/s Ethernet (RoCE)',
            'å­˜å‚¨': '8TB NVMe (2x 4TB)',
            'ç”µæº': '~3.5 kW',
            'ä»·æ ¼': '~$40,000',
            'TCO_3å¹´': '~$55,000',
            'æ€§ä»·æ¯”': 'â­â­â­â­â­'
        }
    
    def compare_configs(self):
        """
        å¯¹æ¯”ä¼ä¸šçº§ vs è‡ªå»º
        """
        dgx = self.dgx_h100_spec()
        custom = self.custom_8gpu_server()
        
        print("GPUæœåŠ¡å™¨é…ç½®å¯¹æ¯”:")
        print("="*70)
        print(f"{'é¡¹ç›®':<20} {'DGX H100 (ä¼ä¸šçº§)':<25} {'è‡ªå»º8x4090':<25}")
        print("-"*70)
        
        keys = ['GPU', 'GPUäº’è”', 'CPU', 'å†…å­˜', 'ç½‘ç»œ', 'ä»·æ ¼', 'TCO_3å¹´']
        for key in keys:
            print(f"{key:<20} {dgx.get(key, 'N/A'):<25} {custom.get(key, 'N/A'):<25}")
        
        print("\né€‰æ‹©å»ºè®®:")
        print("  DGX H100: å¤§å…¬å¸ã€å…³é”®ä»»åŠ¡ã€éœ€è¦æ”¯æŒ")
        print("  è‡ªå»º4090: åˆ›ä¸šå…¬å¸ã€ç ”ç©¶ã€é¢„ç®—æœ‰é™")

config = GPUNodeConfiguration()
config.compare_configs()
```

---

<a name="kubernetes-gpu"></a>
## â˜¸ï¸ 3. Kubernetes + GPU Operator

### 3.1 K8s GPUé›†ç¾¤æ­å»º

```bash
# ============================================
# 1. å‰ç½®å‡†å¤‡
# ============================================

# 1.1 å®‰è£…containerd (æ‰€æœ‰èŠ‚ç‚¹)
sudo apt-get update
sudo apt-get install -y containerd

# é…ç½®containerd
sudo mkdir -p /etc/containerd
containerd config default | sudo tee /etc/containerd/config.toml
sudo systemctl restart containerd

# 1.2 ç¦ç”¨swap (K8sè¦æ±‚)
sudo swapoff -a
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

# 1.3 åŠ è½½å¿…è¦çš„å†…æ ¸æ¨¡å—
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# ============================================
# 2. å®‰è£…Kubernetes (æ‰€æœ‰èŠ‚ç‚¹)
# ============================================

# 2.1 æ·»åŠ K8s aptæº
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl

curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | sudo gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg

echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /' | sudo tee /etc/apt/sources.list.d/kubernetes.list

# 2.2 å®‰è£…kubelet, kubeadm, kubectl
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

# ============================================
# 3. åˆå§‹åŒ–MasterèŠ‚ç‚¹
# ============================================

# 3.1 åˆå§‹åŒ–æ§åˆ¶å¹³é¢ (ä»…MasterèŠ‚ç‚¹)
sudo kubeadm init --pod-network-cidr=10.244.0.0/16

# 3.2 é…ç½®kubectl (MasterèŠ‚ç‚¹)
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

# 3.3 å®‰è£…ç½‘ç»œæ’ä»¶ (Flannel)
kubectl apply -f https://github.com/flannel-io/flannel/releases/latest/download/kube-flannel.yml

# ============================================
# 4. åŠ å…¥WorkerèŠ‚ç‚¹
# ============================================

# 4.1 åœ¨WorkerèŠ‚ç‚¹æ‰§è¡Œ (MasterèŠ‚ç‚¹ä¼šè¾“å‡ºè¿™ä¸ªå‘½ä»¤)
sudo kubeadm join 192.168.1.100:6443 --token <token> \
    --discovery-token-ca-cert-hash sha256:<hash>

# 4.2 éªŒè¯èŠ‚ç‚¹åŠ å…¥ (MasterèŠ‚ç‚¹)
kubectl get nodes

# è¾“å‡ºï¼š
# NAME     STATUS   ROLES           AGE   VERSION
# master   Ready    control-plane   10m   v1.30.0
# worker1  Ready    <none>          5m    v1.30.0
# worker2  Ready    <none>          5m    v1.30.0

# ============================================
# 5. å®‰è£…NVIDIA GPU Operator
# ============================================

# 5.1 æ·»åŠ Helm repo
helm repo add nvidia https://helm.ngc.nvidia.com/nvidia
helm repo update

# 5.2 å®‰è£…GPU Operator
helm install --wait --generate-name \
    -n gpu-operator --create-namespace \
    nvidia/gpu-operator \
    --version=v25.10.1 \
    --set driver.enabled=true

# 5.3 éªŒè¯GPU Operatorå®‰è£…
kubectl get pods -n gpu-operator

# åº”è¯¥çœ‹åˆ°ï¼š
# - nvidia-driver-daemonset (æ¯ä¸ªGPUèŠ‚ç‚¹ä¸€ä¸ª)
# - nvidia-device-plugin-daemonset
# - nvidia-dcgm-exporter (ç›‘æ§)
# - nvidia-operator-validator

# 5.4 éªŒè¯GPUå¯ç”¨
kubectl get nodes -o json | jq '.items[].status.capacity'

# è¾“å‡ºåº”è¯¥åŒ…å«ï¼š
# {
#   "nvidia.com/gpu": "8",  # âœ… æ¯ä¸ªèŠ‚ç‚¹8å—GPU
#   ...
# }
```

---

### 3.2 GPU Podé…ç½®

```yaml
# gpu-training-job.yaml
# GPUè®­ç»ƒä½œä¸šé…ç½®

apiVersion: batch/v1
kind: Job
metadata:
  name: llama2-training
spec:
  template:
    spec:
      # ğŸ”¥ GPUèµ„æºè¯·æ±‚
      containers:
      - name: trainer
        image: nvcr.io/nvidia/pytorch:24.01-py3
        
        # èµ„æºè¯·æ±‚
        resources:
          requests:
            nvidia.com/gpu: 8  # è¯·æ±‚8å—GPU
            memory: "400Gi"
            cpu: "64"
          limits:
            nvidia.com/gpu: 8
            memory: "400Gi"
        
        # ç¯å¢ƒå˜é‡
        env:
          - name: NCCL_DEBUG
            value: "INFO"
          - name: NCCL_IB_DISABLE
            value: "0"  # å¯ç”¨InfiniBand
          - name: NCCL_SOCKET_IFNAME
            value: "ib0"  # InfiniBandç½‘å¡
        
        # æŒ‚è½½å­˜å‚¨
        volumeMounts:
          - name: training-data
            mountPath: /data
          - name: model-output
            mountPath: /output
          - name: shm
            mountPath: /dev/shm  # å…±äº«å†…å­˜ï¼ˆDataLoaderéœ€è¦ï¼‰
        
        # è®­ç»ƒå‘½ä»¤
        command:
          - "torchrun"
          - "--nproc_per_node=8"
          - "--nnodes=1"
          - "train.py"
          - "--config"
          - "/config/train_config.yaml"
      
      # å·é…ç½®
      volumes:
        - name: training-data
          persistentVolumeClaim:
            claimName: lustre-pvc  # Lustreå­˜å‚¨
        - name: model-output
          persistentVolumeClaim:
            claimName: model-output-pvc
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: "64Gi"  # å…±äº«å†…å­˜å¤§å°
      
      # èŠ‚ç‚¹é€‰æ‹©
      nodeSelector:
        gpu-type: h100  # åªè°ƒåº¦åˆ°H100èŠ‚ç‚¹
      
      # å®¹å¿ï¼ˆTolerationï¼‰
      tolerations:
        - key: "nvidia.com/gpu"
          operator: "Exists"
          effect: "NoSchedule"
      
      restartPolicy: OnFailure
```

---

### 3.3 å¤šèŠ‚ç‚¹è®­ç»ƒJobé…ç½®

```yaml
# multi-node-training.yaml
# å¤šèŠ‚ç‚¹åˆ†å¸ƒå¼è®­ç»ƒé…ç½®

apiVersion: kubeflow.org/v1
kind: PyTorchJob
metadata:
  name: llama2-70b-distributed
spec:
  pytorchReplicaSpecs:
    # MasterèŠ‚ç‚¹
    Master:
      replicas: 1
      restartPolicy: OnFailure
      template:
        spec:
          containers:
            - name: pytorch
              image: nvcr.io/nvidia/pytorch:24.01-py3
              resources:
                requests:
                  nvidia.com/gpu: 8
                  memory: "600Gi"
                limits:
                  nvidia.com/gpu: 8
              env:
                - name: NCCL_DEBUG
                  value: "INFO"
                - name: NCCL_IB_HCA
                  value: "mlx5"  # InfiniBandé€‚é…å™¨
              command:
                - python
                - -m
                - torch.distributed.run
                - --nproc_per_node=8
                - --nnodes=8
                - --node_rank=0
                - --master_addr=$(MASTER_ADDR)
                - --master_port=29500
                - train.py
    
    # WorkerèŠ‚ç‚¹
    Worker:
      replicas: 7  # æ€»å…±8ä¸ªèŠ‚ç‚¹ (1 master + 7 workers)
      restartPolicy: OnFailure
      template:
        spec:
          containers:
            - name: pytorch
              image: nvcr.io/nvidia/pytorch:24.01-py3
              resources:
                requests:
                  nvidia.com/gpu: 8
                  memory: "600Gi"
                limits:
                  nvidia.com/gpu: 8
              env:
                - name: NCCL_DEBUG
                  value: "INFO"
                - name: NCCL_IB_HCA
                  value: "mlx5"
              command:
                - python
                - -m
                - torch.distributed.run
                - --nproc_per_node=8
                - --nnodes=8
                - --node_rank=$(RANK)
                - --master_addr=$(MASTER_ADDR)
                - --master_port=29500
                - train.py
```

---

<a name="slurm-scheduling"></a>
## ğŸ“… 4. SLURMä½œä¸šè°ƒåº¦ç³»ç»Ÿ

### 4.1 SLURMæ¶æ„

```python
"""
SLURMæ¶æ„ç»„ä»¶
"""

class SLURMArchitecture:
    """
    SLURM (Simple Linux Utility for Resource Management)
    """
    
    def explain_components(self):
        """
        SLURMæ ¸å¿ƒç»„ä»¶
        """
        print("""
SLURMæ¶æ„:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ç”¨æˆ·æäº¤ä½œä¸š                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚ sbatchâ”‚  â”‚srun  â”‚  â”‚sallocâ”‚                  â”‚
â”‚  â””â”€â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”˜                  â”‚
â”‚      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ§åˆ¶èŠ‚ç‚¹ (slurmctld)                           â”‚
â”‚  - ä½œä¸šè°ƒåº¦                                     â”‚
â”‚  - èµ„æºåˆ†é…                                     â”‚
â”‚  - ä¼˜å…ˆçº§ç®¡ç†                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  è®¡ç®—èŠ‚ç‚¹ (slurmd)                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Node 1   â”‚  â”‚ Node 2   â”‚  â”‚ Node N   â”‚      â”‚
â”‚  â”‚ 8xH100   â”‚  â”‚ 8xH100   â”‚  â”‚ 8xH100   â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  æ•°æ®åº“ (slurmdbd)                              â”‚
â”‚  - ä½œä¸šå†å²                                     â”‚
â”‚  - èµ„æºä½¿ç”¨ç»Ÿè®¡                                 â”‚
â”‚  - ç”¨æˆ·é…é¢                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """)

arch = SLURMArchitecture()
arch.explain_components()
```

---

### 4.2 SLURMé…ç½®

```bash
# ============================================
# slurm.conf - SLURMä¸»é…ç½®æ–‡ä»¶
# ============================================

# é›†ç¾¤åç§°
ClusterName=ml-training-cluster

# æ§åˆ¶èŠ‚ç‚¹
SlurmctldHost=master-node

# è°ƒåº¦å™¨é…ç½®
SchedulerType=sched/backfill
SelectType=select/cons_tres  # æ”¯æŒGRES (GPU)
SelectTypeParameters=CR_Core_Memory

# èµ„æºé…ç½®
GresTypes=gpu

# ä¼˜å…ˆçº§
PriorityType=priority/multifactor
PriorityWeightAge=1000
PriorityWeightFairshare=10000
PriorityWeightJobSize=1000
PriorityWeightQOS=10000

# ä½œä¸šæ—¶é—´é™åˆ¶
MaxJobCount=10000
MaxTaskCount=100000

# è´¦æˆ·é…ç½®
AccountingStorageType=accounting_storage/slurmdbd
AccountingStorageHost=db-node
AccountingStoragePort=6819

# ============================================
# è®¡ç®—èŠ‚ç‚¹é…ç½®
# ============================================

# GPUèŠ‚ç‚¹ (H100)
NodeName=gpu-node[1-8] \
    Sockets=2 \
    CoresPerSocket=28 \
    ThreadsPerCore=2 \
    RealMemory=512000 \
    Gres=gpu:h100:8 \
    State=UNKNOWN

# åˆ†åŒºé…ç½® (Partition)
PartitionName=gpu \
    Nodes=gpu-node[1-8] \
    Default=YES \
    MaxTime=7-00:00:00 \
    State=UP \
    OverSubscribe=NO \
    PriorityJobFactor=10

PartitionName=gpu-short \
    Nodes=gpu-node[1-2] \
    Default=NO \
    MaxTime=04:00:00 \
    State=UP \
    PriorityJobFactor=5

# ============================================
# gres.conf - GPUé…ç½®
# ============================================

# è‡ªåŠ¨æ£€æµ‹GPU (SLURM 24.11+)
AutoDetect=nvml

# æˆ–æ‰‹åŠ¨é…ç½®
# NodeName=gpu-node1 Name=gpu Type=h100 File=/dev/nvidia[0-7]
# NodeName=gpu-node2 Name=gpu Type=h100 File=/dev/nvidia[0-7]
```

---

### 4.3 SLURMä½œä¸šæäº¤

```bash
# ============================================
# å•èŠ‚ç‚¹8å¡è®­ç»ƒ
# ============================================

#!/bin/bash
#SBATCH --job-name=llama2-7b-train
#SBATCH --partition=gpu
#SBATCH --nodes=1              # å•èŠ‚ç‚¹
#SBATCH --gres=gpu:8           # ğŸ”¥ è¯·æ±‚8å—GPU
#SBATCH --cpus-per-task=64     # CPUæ ¸å¿ƒ
#SBATCH --mem=400G             # å†…å­˜
#SBATCH --time=48:00:00        # æœ€é•¿è¿è¡Œæ—¶é—´
#SBATCH --output=logs/train_%j.out
#SBATCH --error=logs/train_%j.err

# åŠ è½½æ¨¡å—
module load cuda/11.8
module load nccl/2.17

# æ¿€æ´»condaç¯å¢ƒ
conda activate llm-training

# è®¾ç½®ç¯å¢ƒå˜é‡
export NCCL_DEBUG=INFO
export NCCL_IB_DISABLE=0

# è¿è¡Œè®­ç»ƒ
torchrun --nproc_per_node=8 \
    train.py \
    --config configs/train_config.yaml

# ============================================
# å¤šèŠ‚ç‚¹64å¡è®­ç»ƒ
# ============================================

#!/bin/bash
#SBATCH --job-name=llama2-70b-train
#SBATCH --partition=gpu
#SBATCH --nodes=8              # 8ä¸ªèŠ‚ç‚¹
#SBATCH --gres=gpu:8           # æ¯èŠ‚ç‚¹8å—GPU
#SBATCH --ntasks-per-node=1    # æ¯èŠ‚ç‚¹1ä¸ªä»»åŠ¡
#SBATCH --cpus-per-task=64
#SBATCH --mem=400G
#SBATCH --time=168:00:00       # 7å¤©
#SBATCH --output=logs/train_%j.out
#SBATCH --error=logs/train_%j.err

# è·å–èŠ‚ç‚¹åˆ—è¡¨
export MASTER_ADDR=$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)
export MASTER_PORT=29500
export WORLD_SIZE=$((SLURM_NNODES * 8))  # æ€»GPUæ•°

# åœ¨æ¯ä¸ªèŠ‚ç‚¹å¯åŠ¨è®­ç»ƒ
srun torchrun \
    --nnodes=$SLURM_NNODES \
    --nproc_per_node=8 \
    --node_rank=$SLURM_NODEID \
    --master_addr=$MASTER_ADDR \
    --master_port=$MASTER_PORT \
    train.py \
    --config configs/train_config.yaml

# æäº¤ä½œä¸š
sbatch train_job.sh

# æŸ¥çœ‹ä½œä¸šçŠ¶æ€
squeue -u $USER

# è¾“å‡ºï¼š
#  JOBID PARTITION     NAME     USER ST       TIME  NODES
#  12345       gpu llama2-7  john  R      10:30      1

# æŸ¥çœ‹è¯¦ç»†ä¿¡æ¯
scontrol show job 12345

# å–æ¶ˆä½œä¸š
scancel 12345

# æŸ¥çœ‹GPUä½¿ç”¨æƒ…å†µ
squeue -o "%.18i %.9P %.8j %.8u %.2t %.10M %.6D %.20R %b"
```

---

<a name="high-performance-storage"></a>
## ğŸ’¾ 5. é«˜æ€§èƒ½å­˜å‚¨ï¼šLustre vs GPFS

### 5.1 Lustreæ¶æ„

æ ¹æ® [AWS FSx for Lustre](https://aws.amazon.com/fsx/lustre/) å’Œ [Google Managed Lustre](https://cloud.google.com/managed-lustre/docs/overview)ï¼š

```python
"""
Lustreæ–‡ä»¶ç³»ç»Ÿæ¶æ„
"""

class LustreArchitecture:
    """
    Lustreåˆ†å¸ƒå¼æ–‡ä»¶ç³»ç»Ÿ
    """
    
    def explain_architecture(self):
        """
        Lustreæ¶æ„è¯´æ˜
        """
        print("""
Lustreæ–‡ä»¶ç³»ç»Ÿæ¶æ„:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å®¢æˆ·ç«¯ (Compute Nodes)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚ GPU  â”‚  â”‚ GPU  â”‚  â”‚ GPU  â”‚           â”‚
â”‚  â”‚ Node â”‚  â”‚ Node â”‚  â”‚ Node â”‚           â”‚
â”‚  â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜  â””â”€â”€â”¬â”€â”€â”€â”˜           â”‚
â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“ Lustre Client
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å…ƒæ•°æ®æœåŠ¡å™¨ (MGS/MDS)                   â”‚
â”‚  - æ–‡ä»¶å                                 â”‚
â”‚  - ç›®å½•ç»“æ„                               â”‚
â”‚  - æƒé™ä¿¡æ¯                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  å¯¹è±¡å­˜å‚¨æœåŠ¡å™¨ (OSS/OST)                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ OST 1  â”‚  â”‚ OST 2  â”‚  â”‚ OST N  â”‚      â”‚
â”‚  â”‚ 100TB  â”‚  â”‚ 100TB  â”‚  â”‚ 100TB  â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚  (æ•°æ®åˆ†æ¡å¸¦å­˜å‚¨ï¼Œå¹¶è¡Œè¯»å†™)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """)
        
        print("\nLustreç‰¹ç‚¹:")
        print("  âœ… PBçº§å®¹é‡")
        print("  âœ… TB/sçº§åå")
        print("  âœ… æ•°ç™¾ä¸‡IOPS")
        print("  âœ… äºšæ¯«ç§’å»¶è¿Ÿ")
        print("  âœ… POSIXå…¼å®¹ï¼ˆåƒæœ¬åœ°æ–‡ä»¶ç³»ç»Ÿï¼‰")
    
    def performance_specs(self):
        """
        Lustreæ€§èƒ½è§„æ ¼ï¼ˆ2025ï¼‰
        """
        specs = {
            'AWS FSx for Lustre': {
                'ååé‡': 'æœ€é«˜ 1200 GB/s per client',
                'å®¹é‡': 'PBçº§',
                'IOPS': 'æ•°ç™¾ä¸‡',
                'å»¶è¿Ÿ': 'äºšæ¯«ç§’',
                'ä»·æ ¼': '$0.005/GB-æœˆ èµ·',
                'é›†æˆ': 'SageMaker HyperPod'
            },
            
            'Google Managed Lustre': {
                'ååé‡': 'æœ€é«˜ 1 TB/s',
                'å®¹é‡': 'PBçº§',
                'IOPS': 'æé«˜',
                'å»¶è¿Ÿ': 'ä½',
                'é›†æˆ': 'GKE, Compute Engine'
            },
            
            'è‡ªå»ºLustre': {
                'ååé‡': 'å–å†³äºOSTæ•°é‡',
                'å®¹é‡': 'å¯æ‰©å±•åˆ°EBçº§',
                'IOPS': 'å¯æ‰©å±•',
                'å»¶è¿Ÿ': 'å–å†³äºç¡¬ä»¶',
                'ä»·æ ¼': 'ç¡¬ä»¶æˆæœ¬',
                'çµæ´»æ€§': 'â­â­â­â­â­'
            }
        }
        
        import pandas as pd
        df = pd.DataFrame(specs).T
        print("\nLustreæ–¹æ¡ˆå¯¹æ¯”:")
        print(df.to_string())

arch = LustreArchitecture()
arch.explain_architecture()
arch.performance_specs()
```

---

### 5.2 Lustreé›†ç¾¤æ­å»º

```bash
# ============================================
# Lustreé›†ç¾¤éƒ¨ç½² (è‡ªå»º)
# ============================================

# === æœåŠ¡å™¨è§„åˆ’ ===
# MGS/MDS: 1å° (å…ƒæ•°æ®æœåŠ¡å™¨)
# OSS: 4å° (å¯¹è±¡å­˜å‚¨æœåŠ¡å™¨ï¼Œæ¯å°æŒ‚è½½2ä¸ªOST)
# å®¢æˆ·ç«¯: Nå°GPUè®­ç»ƒèŠ‚ç‚¹

# === 1. MGS/MDSèŠ‚ç‚¹é…ç½® ===

# 1.1 å®‰è£…Lustreè½¯ä»¶
sudo apt-get install lustre-server-utils

# 1.2 åˆ›å»ºMGS
sudo mkfs.lustre --mgs /dev/sdb  # sdbæ˜¯MGSä¸“ç”¨ç›˜

# 1.3 æŒ‚è½½MGS
sudo mkdir -p /mnt/mgs
sudo mount -t lustre /dev/sdb /mnt/mgs

# 1.4 åˆ›å»ºMDS
sudo mkfs.lustre \
    --mdt \
    --fsname=mlfs \  # æ–‡ä»¶ç³»ç»Ÿåç§°
    --mgsnode=192.168.1.10@tcp \  # MGSåœ°å€
    --index=0 \
    /dev/sdc  # sdcæ˜¯MDSä¸“ç”¨ç›˜

# 1.5 æŒ‚è½½MDS
sudo mkdir -p /mnt/mdt
sudo mount -t lustre /dev/sdc /mnt/mdt

# === 2. OSSèŠ‚ç‚¹é…ç½® (æ¯ä¸ªOSSèŠ‚ç‚¹) ===

# 2.1 å®‰è£…Lustre
sudo apt-get install lustre-server-utils

# 2.2 åˆ›å»ºOST (æ¯ä¸ªOSSåˆ›å»º2ä¸ªOST)
# OSSèŠ‚ç‚¹1
sudo mkfs.lustre \
    --ost \
    --fsname=mlfs \
    --mgsnode=192.168.1.10@tcp \
    --index=0 \
    /dev/sdb  # OST 0

sudo mkfs.lustre \
    --ost \
    --fsname=mlfs \
    --mgsnode=192.168.1.10@tcp \
    --index=1 \
    /dev/sdc  # OST 1

# 2.3 æŒ‚è½½OST
sudo mkdir -p /mnt/ost0 /mnt/ost1
sudo mount -t lustre /dev/sdb /mnt/ost0
sudo mount -t lustre /dev/sdc /mnt/ost1

# === 3. å®¢æˆ·ç«¯é…ç½® (GPUè®­ç»ƒèŠ‚ç‚¹) ===

# 3.1 å®‰è£…Lustreå®¢æˆ·ç«¯
sudo apt-get install lustre-client-dkms

# 3.2 æŒ‚è½½Lustreæ–‡ä»¶ç³»ç»Ÿ
sudo mkdir -p /mnt/lustre
sudo mount -t lustre 192.168.1.10@tcp:/mlfs /mnt/lustre

# 3.3 éªŒè¯
df -h /mnt/lustre
lfs df -h  # Lustreä¸“ç”¨å‘½ä»¤

# è¾“å‡ºï¼š
# filesystem_summary:  400.0T  100.0T  300.0T   25% /mnt/lustre[OST:8]

# === 4. æ€§èƒ½è°ƒä¼˜ ===

# 4.1 è®¾ç½®æ¡å¸¦åŒ–ï¼ˆStripingï¼‰
lfs setstripe -c 4 /mnt/lustre/training_data  # 4ä¸ªOSTå¹¶è¡Œ

# 4.2 æŸ¥çœ‹æ¡å¸¦é…ç½®
lfs getstripe /mnt/lustre/training_data

# 4.3 ä¼˜åŒ–å¤§æ–‡ä»¶è¯»å†™
lfs setstripe -c -1 /mnt/lustre/checkpoints  # ä½¿ç”¨æ‰€æœ‰OST
```

---

### 5.3 Lustreæ€§èƒ½æµ‹è¯•

```python
"""
Lustreæ€§èƒ½Benchmark
"""

import subprocess
import time
import os

class LustrePerformanceBenchmark:
    """
    Lustreæ€§èƒ½æµ‹è¯•
    """
    
    def test_sequential_write(self, file_size_gb=10, lustre_path='/mnt/lustre'):
        """
        æµ‹è¯•é¡ºåºå†™æ€§èƒ½
        """
        file_path = os.path.join(lustre_path, 'benchmark_write.dat')
        file_size_bytes = file_size_gb * 1024 ** 3
        
        print(f"æµ‹è¯•é¡ºåºå†™ ({file_size_gb}GB)...")
        
        # ä½¿ç”¨ddæµ‹è¯•
        start = time.time()
        subprocess.run([
            'dd',
            'if=/dev/zero',
            f'of={file_path}',
            f'bs=1M',
            f'count={file_size_gb * 1024}',
            'conv=fsync'
        ], check=True, capture_output=True)
        duration = time.time() - start
        
        bandwidth_gbps = file_size_gb / duration
        print(f"  å†™å¸¦å®½: {bandwidth_gbps:.2f} GB/s")
        
        return bandwidth_gbps
    
    def test_sequential_read(self, file_size_gb=10, lustre_path='/mnt/lustre'):
        """
        æµ‹è¯•é¡ºåºè¯»æ€§èƒ½
        """
        file_path = os.path.join(lustre_path, 'benchmark_write.dat')
        
        print(f"æµ‹è¯•é¡ºåºè¯» ({file_size_gb}GB)...")
        
        # æ¸…é™¤ç¼“å­˜
        subprocess.run(['sudo', 'sh', '-c', 'echo 3 > /proc/sys/vm/drop_caches'])
        
        # ä½¿ç”¨ddæµ‹è¯•
        start = time.time()
        subprocess.run([
            'dd',
            f'if={file_path}',
            'of=/dev/null',
            'bs=1M'
        ], check=True, capture_output=True)
        duration = time.time() - start
        
        bandwidth_gbps = file_size_gb / duration
        print(f"  è¯»å¸¦å®½: {bandwidth_gbps:.2f} GB/s")
        
        return bandwidth_gbps
    
    def test_iops(self, lustre_path='/mnt/lustre'):
        """
        æµ‹è¯•IOPS (ä½¿ç”¨fio)
        """
        print("æµ‹è¯•éšæœºè¯»å†™IOPS...")
        
        # ä½¿ç”¨fioå·¥å…·
        fio_config = f"""
[global]
directory={lustre_path}
size=10G
direct=1
ioengine=libaio
iodepth=32
numjobs=4

[random-read]
rw=randread
bs=4k

[random-write]
rw=randwrite
bs=4k
"""
        
        with open('/tmp/fio_config.ini', 'w') as f:
            f.write(fio_config)
        
        result = subprocess.run(
            ['fio', '/tmp/fio_config.ini'],
            capture_output=True,
            text=True
        )
        
        # è§£æç»“æœ
        lines = result.stdout.split('\n')
        for line in lines:
            if 'IOPS=' in line:
                print(f"  {line.strip()}")

# è¿è¡ŒBenchmark
benchmark = LustrePerformanceBenchmark()
write_bw = benchmark.test_sequential_write(file_size_gb=10)
read_bw = benchmark.test_sequential_read(file_size_gb=10)
benchmark.test_iops()

# å…¸å‹ç»“æœï¼š
# é¡ºåºå†™: 8-15 GB/s (å–å†³äºOSTæ•°é‡)
# é¡ºåºè¯»: 10-20 GB/s
# éšæœºè¯»IOPS: 100K-500K
# éšæœºå†™IOPS: 50K-200K
```

---

### 5.4 DataLoader with Lustreä¼˜åŒ–

```python
"""
PyTorch DataLoader + Lustreä¼˜åŒ–
"""

import torch
from torch.utils.data import DataLoader, Dataset
import os

class LustreOptimizedDataLoader:
    """
    é’ˆå¯¹Lustreä¼˜åŒ–çš„DataLoaderé…ç½®
    """
    
    def create_dataloader(
        self,
        dataset,
        batch_size=32,
        num_workers=8,
        prefetch_factor=2
    ):
        """
        Lustreä¼˜åŒ–çš„DataLoader
        
        å…³é”®ä¼˜åŒ–ï¼š
        1. num_workersé€‚ä¸­ï¼ˆ8-16ï¼Œä¸æ˜¯è¶Šå¤šè¶Šå¥½ï¼‰
        2. prefetch_factoré€‚ä¸­ï¼ˆ2-4ï¼‰
        3. pin_memory=True
        4. persistent_workers=True
        """
        dataloader = DataLoader(
            dataset,
            batch_size=batch_size,
            
            # ğŸ”¥ Lustreä¼˜åŒ–å‚æ•°
            num_workers=8,              # é€‚ä¸­workeræ•°
            prefetch_factor=2,           # é¢„å–å› å­
            pin_memory=True,             # å›ºå®šå†…å­˜ï¼ˆåŠ é€ŸGPUä¼ è¾“ï¼‰
            persistent_workers=True,     # ä¿æŒworkerè¿›ç¨‹
            
            shuffle=True
        )
        
        return dataloader
    
    def optimize_file_layout(self, data_dir='/mnt/lustre/training_data'):
        """
        ä¼˜åŒ–Lustreæ–‡ä»¶å¸ƒå±€
        """
        print("Lustreæ–‡ä»¶å¸ƒå±€ä¼˜åŒ–:")
        
        # 1. å¤§æ–‡ä»¶ï¼šä½¿ç”¨æ›´å¤šOST
        os.system(f"lfs setstripe -c -1 {data_dir}/large_files")  # æ‰€æœ‰OST
        
        # 2. å°æ–‡ä»¶ï¼šä½¿ç”¨å°‘é‡OSTï¼ˆå‡å°‘å…ƒæ•°æ®å‹åŠ›ï¼‰
        os.system(f"lfs setstripe -c 1 {data_dir}/small_files")
        
        # 3. Checkpointç›®å½•ï¼šé«˜æ¡å¸¦æ•°
        os.system(f"lfs setstripe -c 8 {data_dir}/checkpoints")
        
        print("âœ… æ–‡ä»¶å¸ƒå±€å·²ä¼˜åŒ–")
    
    def benchmark_data_loading(self, dataloader):
        """
        Benchmarkæ•°æ®åŠ è½½é€Ÿåº¦
        """
        import time
        
        print("\nDataLoaderæ€§èƒ½æµ‹è¯•:")
        
        # Warmup
        for _ in range(10):
            batch = next(iter(dataloader))
        
        # Benchmark
        start = time.time()
        num_batches = 100
        for i, batch in enumerate(dataloader):
            if i >= num_batches:
                break
        duration = time.time() - start
        
        batches_per_sec = num_batches / duration
        samples_per_sec = batches_per_sec * dataloader.batch_size
        
        print(f"  ååé‡: {batches_per_sec:.2f} batches/s")
        print(f"  æ ·æœ¬/ç§’: {samples_per_sec:.0f}")
        print(f"  å¹³å‡batchæ—¶é—´: {duration/num_batches*1000:.1f}ms")
        
        # ç“¶é¢ˆè¯Šæ–­
        if batches_per_sec < 10:
            print("  âš ï¸ æ•°æ®åŠ è½½æ…¢ï¼Œå¯èƒ½ç“¶é¢ˆï¼š")
            print("    - Lustre IOæ…¢ï¼ˆæ£€æŸ¥lfs dfï¼‰")
            print("    - num_workerså¤ªå°‘ï¼ˆå¢åŠ åˆ°16ï¼‰")
            print("    - æ•°æ®é¢„å¤„ç†æ…¢ï¼ˆä¼˜åŒ–transformï¼‰")

optimizer = LustreOptimizedDataLoader()
dataloader = optimizer.create_dataloader(dataset)
optimizer.benchmark_data_loading(dataloader)
```

---

<a name="network-optimization"></a>
## ğŸŒ 6. ç½‘ç»œä¼˜åŒ–ï¼šRDMA & InfiniBand

### 6.1 RDMAåŸç†

```python
"""
RDMA (Remote Direct Memory Access) åŸç†
"""

class RDMAExplainer:
    """
    RDMA vs ä¼ ç»ŸTCP/IP
    """
    
    def compare_network_stacks(self):
        """
        å¯¹æ¯”RDMAå’ŒTCP/IP
        """
        print("ç½‘ç»œé€šä¿¡å¯¹æ¯”:")
        print("="*70)
        
        print("\nä¼ ç»ŸTCP/IP:")
        print("""
        GPU Memory â†’ CPU Memory â†’ TCP Stack â†’ NIC â†’ Network
                      â†‘            â†‘          â†‘
                   CPUæ‹·è´      CPUå¤„ç†    ä¸­æ–­/ä¸Šä¸‹æ–‡åˆ‡æ¢
        
        é—®é¢˜ï¼š
        - CPUå‚ä¸æ•°æ®ä¼ è¾“ï¼ˆå ç”¨CPUï¼‰
        - å¤šæ¬¡å†…å­˜æ‹·è´ï¼ˆæ…¢ï¼‰
        - å†…æ ¸åè®®æ ˆå¼€é”€ï¼ˆå»¶è¿Ÿé«˜ï¼‰
        """)
        
        print("\nRDMA (InfiniBand):")
        print("""
        GPU Memory â†’ RDMA NIC â†’ Network â†’ RDMA NIC â†’ GPU Memory
                      â†‘                                  â†‘
                ç›´æ¥è®¿é—®ï¼ˆZero-copyï¼‰            ç›´æ¥å†™å…¥
        
        ä¼˜åŠ¿ï¼š
        âœ… é›¶æ‹·è´ï¼ˆZero-copyï¼‰
        âœ… å†…æ ¸æ—è·¯ï¼ˆKernel bypassï¼‰
        âœ… CPUå¸è½½ï¼ˆCPU offloadï¼‰
        âœ… ä½å»¶è¿Ÿï¼ˆ<2å¾®ç§’ï¼‰
        âœ… é«˜å¸¦å®½ï¼ˆ400 Gb/sï¼‰
        """)
    
    def latency_comparison(self):
        """
        å»¶è¿Ÿå¯¹æ¯”
        """
        latencies = {
            'ç½‘ç»œç±»å‹': ['å»¶è¿Ÿ', 'å¸¦å®½', 'é€‚ç”¨åœºæ™¯'],
            
            'TCP/IP (Ethernet)': [
                '50-100 Î¼s',
                '100 Gb/s',
                'å•æœº/å°è§„æ¨¡'
            ],
            
            'RDMA over Converged Ethernet (RoCE)': [
                '5-10 Î¼s',
                '200 Gb/s',
                'ä¸­ç­‰è§„æ¨¡'
            ],
            
            'InfiniBand': [
                '1-2 Î¼s',
                '400 Gb/s',
                'ğŸ”¥ å¤§è§„æ¨¡è®­ç»ƒ'
            ]
        }
        
        import pandas as pd
        df = pd.DataFrame(latencies).set_index('ç½‘ç»œç±»å‹')
        print("\nç½‘ç»œå»¶è¿Ÿå¯¹æ¯”:")
        print(df.to_string())
        
        print("\nğŸ”¥ ç»“è®ºï¼šInfiniBandæ˜¯å¤§è§„æ¨¡è®­ç»ƒçš„æ ‡é…")

explainer = RDMAExplainer()
explainer.compare_network_stacks()
explainer.latency_comparison()
```

---

### 6.2 InfiniBandé›†ç¾¤é…ç½®

```bash
# ============================================
# InfiniBandç½‘ç»œé…ç½®
# ============================================

# === 1. å®‰è£…Mellanox OFEDé©±åŠ¨ ===

# 1.1 ä¸‹è½½MLNX_OFED (æ‰€æœ‰èŠ‚ç‚¹)
wget https://www.mellanox.com/downloads/ofed/MLNX_OFED-24.10-1.0.0.0/MLNX_OFED_LINUX-24.10-1.0.0.0-ubuntu22.04-x86_64.tgz

tar -xzvf MLNX_OFED_LINUX-24.10-1.0.0.0-ubuntu22.04-x86_64.tgz
cd MLNX_OFED_LINUX-24.10-1.0.0.0-ubuntu22.04-x86_64

# 1.2 å®‰è£…
sudo ./mlnxofedinstall --force

# 1.3 é‡å¯OFEDæœåŠ¡
sudo /etc/init.d/openibd restart

# 1.4 éªŒè¯å®‰è£…
ibstat

# è¾“å‡ºåº”è¯¥æ˜¾ç¤ºIBç½‘å¡ä¿¡æ¯ï¼š
# CA 'mlx5_0'
#     CA type: MT4123
#     Number of ports: 1
#     Firmware version: 28.42.1000
#     Port 1:
#         State: Active
#         Physical state: LinkUp
#         Rate: 400 Gb/s
#         Link layer: InfiniBand

# === 2. é…ç½®IP over IB (IPoIB) ===

# 2.1 é…ç½®IBç½‘å¡IP
sudo ip addr add 10.0.0.1/24 dev ib0  # æ ¹æ®èŠ‚ç‚¹ç¼–å·ä¿®æ”¹
sudo ip link set ib0 up

# 2.2 æµ‹è¯•IBç½‘ç»œè¿é€šæ€§
ping -I ib0 10.0.0.2  # Pingå…¶ä»–èŠ‚ç‚¹

# === 3. é…ç½®GPUDirect RDMA ===

# 3.1 åŠ è½½nv_peer_memæ¨¡å—
sudo modprobe nv_peer_mem

# 3.2 éªŒè¯
lsmod | grep nv_peer_mem

# === 4. æ€§èƒ½æµ‹è¯• ===

# 4.1 IBå¸¦å®½æµ‹è¯• (ä¸¤èŠ‚ç‚¹ä¹‹é—´)
# èŠ‚ç‚¹1 (server):
ib_write_bw

# èŠ‚ç‚¹2 (client):
ib_write_bw 10.0.0.1

# è¾“å‡ºï¼š
#  #bytes     #iterations    BW peak[GB/sec]    BW average[GB/sec]
#  65536      5000           48.92              48.88

# 4.2 GPU-GPU RDMAæµ‹è¯•
ib_write_bw -d mlx5_0 -a --use_cuda=0  # ä½¿ç”¨GPU 0

# è¾“å‡ºåº”è¯¥æ˜¾ç¤ºGPUDirect RDMAç”Ÿæ•ˆ
```

---

### 6.3 NCCLä¸InfiniBandé›†æˆ

```python
"""
NCCLé…ç½®InfiniBand
"""

import os

class NCCLInfiniBandConfig:
    """
    NCCL + InfiniBandé…ç½®
    """
    
    def set_environment_variables(self):
        """
        è®¾ç½®NCCLç¯å¢ƒå˜é‡
        """
        env_vars = {
            # === InfiniBandé…ç½® ===
            'NCCL_IB_DISABLE': '0',              # å¯ç”¨IB
            'NCCL_IB_HCA': 'mlx5',               # IBé€‚é…å™¨å‰ç¼€
            'NCCL_IB_GID_INDEX': '3',            # GIDç´¢å¼•ï¼ˆRoCEç”¨ï¼‰
            
            # === GPUDirect RDMA ===
            'NCCL_IB_CUDA_SUPPORT': '1',         # å¯ç”¨GPUDirect
            
            # === æ€§èƒ½è°ƒä¼˜ ===
            'NCCL_IB_TIMEOUT': '22',             # è¶…æ—¶ï¼ˆé»˜è®¤18ï¼‰
            'NCCL_IB_QPS_PER_CONNECTION': '4',   # æ¯è¿æ¥QPæ•°
            'NCCL_IB_TC': '106',                 # Traffic Class
            
            # === è°ƒè¯• ===
            'NCCL_DEBUG': 'INFO',                # è°ƒè¯•çº§åˆ«
            'NCCL_DEBUG_SUBSYS': 'INIT,NET',     # å­ç³»ç»Ÿè°ƒè¯•
            
            # === ç½‘å¡é€‰æ‹© ===
            'NCCL_SOCKET_IFNAME': 'ib0',         # ä½¿ç”¨IBç½‘å¡
            'NCCL_NET_GDR_LEVEL': '5',           # GPUDirectç­‰çº§
        }
        
        print("NCCL InfiniBandç¯å¢ƒå˜é‡é…ç½®:")
        print("="*70)
        for key, value in env_vars.items():
            print(f"export {key}={value}")
            os.environ[key] = str(value)
        
        print("\nâœ… NCCLå·²é…ç½®ä½¿ç”¨InfiniBand")
    
    def verify_nccl_ib(self):
        """
        éªŒè¯NCCLä½¿ç”¨InfiniBand
        """
        print("\néªŒè¯NCCLé…ç½®:")
        print("="*70)
        
        # è¿è¡Œç®€å•çš„NCCLæµ‹è¯•
        test_script = """
import torch
import torch.distributed as dist

dist.init_process_group(backend='nccl')
rank = dist.get_rank()
world_size = dist.get_world_size()

tensor = torch.ones(1024, 1024).cuda(rank)
dist.all_reduce(tensor)

if rank == 0:
    print("âœ… NCCL AllReduceæˆåŠŸ")
"""
        
        print("è¿è¡ŒNCCLæµ‹è¯•...")
        print("æŸ¥çœ‹æ—¥å¿—ä¸­çš„ç½‘ç»œç±»å‹ï¼š")
        print("  [INFO] NET/IB : Using [0]mlx5_0:1/IB")
        print("  â†‘ è¯´æ˜æ­£åœ¨ä½¿ç”¨InfiniBand")

config = NCCLInfiniBandConfig()
config.set_environment_variables()
config.verify_nccl_ib()
```

---

<a name="cost-optimization"></a>
## ğŸ’° 7. æˆæœ¬ä¼˜åŒ–ï¼šSpotå®ä¾‹ä¸æ··åˆäº‘

### 7.1 Spotå®ä¾‹ç­–ç•¥

æ ¹æ® [AWS Spot Instancesæœ€ä½³å®è·µ](https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-spot-instances/spot-best-practices.html)ï¼š

```python
"""
Spotå®ä¾‹æˆæœ¬ä¼˜åŒ–
"""

class SpotInstanceOptimization:
    """
    Spotå®ä¾‹ä¼˜åŒ–ç­–ç•¥
    
    èŠ‚çœï¼šæœ€é«˜90%æˆæœ¬
    é£é™©ï¼šå¯èƒ½è¢«ä¸­æ–­ï¼ˆ2åˆ†é’Ÿé€šçŸ¥ï¼‰
    """
    
    def calculate_savings(self):
        """
        è®¡ç®—Spotå®ä¾‹èŠ‚çœ
        """
        # 2025å¹´AWS GPUå®ä¾‹ä»·æ ¼
        pricing = {
            'p4d.24xlarge (8xA100 40GB)': {
                'on_demand': 32.77,  # $/hour
                'spot_avg': 9.83,    # $/hour (å¹³å‡)
                'saving': 0.70
            },
            'p5.48xlarge (8xH100 80GB)': {
                'on_demand': 98.32,
                'spot_avg': 29.50,
                'saving': 0.70
            },
            'g5.48xlarge (8xA10G 24GB)': {
                'on_demand': 16.29,
                'spot_avg': 4.89,
                'saving': 0.70
            }
        }
        
        print("Spotå®ä¾‹ä»·æ ¼å¯¹æ¯”ï¼ˆAWSï¼Œ2025ï¼‰:")
        print("="*70)
        for instance, prices in pricing.items():
            print(f"\n{instance}:")
            print(f"  On-Demand: ${prices['on_demand']:.2f}/hour")
            print(f"  Spotå‡ä»·:  ${prices['spot_avg']:.2f}/hour")
            print(f"  èŠ‚çœ:      {prices['saving']:.0%}")
            
            # è®­ç»ƒ7å¤©æˆæœ¬
            hours = 7 * 24
            on_demand_cost = prices['on_demand'] * hours
            spot_cost = prices['spot_avg'] * hours
            
            print(f"  7å¤©è®­ç»ƒæˆæœ¬:")
            print(f"    On-Demand: ${on_demand_cost:,.0f}")
            print(f"    Spot:      ${spot_cost:,.0f}")
            print(f"    èŠ‚çœ:      ${on_demand_cost - spot_cost:,.0f}")
    
    def spot_interruption_handling(self):
        """
        Spotä¸­æ–­å¤„ç†ç­–ç•¥
        """
        print("\nSpotå®ä¾‹ä¸­æ–­å¤„ç†:")
        print("="*70)
        
        strategies = {
            '1. Checkpointé¢‘ç¹ä¿å­˜': {
                'description': 'æ¯Næ­¥ä¿å­˜checkpoint',
                'code': '''
# æ¯100æ­¥ä¿å­˜checkpoint
if step % 100 == 0:
    save_checkpoint(model, optimizer, step)
''',
                'recovery_time': 'æŸå¤±<100æ­¥è®­ç»ƒ'
            },
            
            '2. ç›‘å¬ä¸­æ–­ä¿¡å·': {
                'description': 'AWSä¼šåœ¨2åˆ†é’Ÿå‰å‘é€ä¸­æ–­é€šçŸ¥',
                'code': '''
# ç›‘å¬EC2å…ƒæ•°æ®æœåŠ¡
import requests
import signal

def check_spot_interruption():
    try:
        r = requests.get(
            'http://169.254.169.254/latest/meta-data/spot/instance-action',
            timeout=1
        )
        if r.status_code == 200:
            print("âš ï¸ Spotä¸­æ–­é€šçŸ¥ï¼ä¿å­˜checkpoint...")
            save_checkpoint(model, optimizer, step)
            exit(0)
    except:
        pass

# æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
while training:
    check_spot_interruption()
    time.sleep(30)
''',
                'recovery_time': '0æŸå¤±ï¼ˆæå‰ä¿å­˜ï¼‰'
            },
            
            '3. Checkpointåˆ°æŒä¹…åŒ–å­˜å‚¨': {
                'description': 'ä¿å­˜åˆ°S3/EBSè€Œéæœ¬åœ°',
                'code': '''
# ä¿å­˜åˆ°S3
import boto3

s3 = boto3.client('s3')
torch.save(checkpoint, '/tmp/checkpoint.pth')
s3.upload_file(
    '/tmp/checkpoint.pth',
    'my-bucket',
    f'checkpoints/checkpoint_step_{step}.pth'
)
''',
                'recovery_time': 'æ–°å®ä¾‹å¯ç«‹å³æ¢å¤'
            },
            
            '4. å¤šå®ä¾‹ç±»å‹fallback': {
                'description': 'é…ç½®å¤šç§Spotå®ä¾‹ç±»å‹',
                'code': '''
# EC2 Auto Scalingé…ç½®
{
  "OverrideInstances": [
    {"InstanceType": "p4d.24xlarge"},
    {"InstanceType": "p3dn.24xlarge"},  # fallback
    {"InstanceType": "p3.16xlarge"}      # fallback 2
  ],
  "SpotAllocationStrategy": "price-capacity-optimized"
}
''',
                'recovery_time': 'è‡ªåŠ¨åˆ‡æ¢åˆ°å…¶ä»–ç±»å‹'
            }
        }
        
        for strategy, details in strategies.items():
            print(f"\n{strategy}")
            print(f"  {details['description']}")
            print(f"  æ¢å¤æ—¶é—´: {details['recovery_time']}")
            if 'code' in details:
                print(f"  ä»£ç ç¤ºä¾‹:")
                for line in details['code'].strip().split('\n'):
                    print(f"    {line}")

optimizer = SpotInstanceOptimization()
optimizer.calculate_savings()
optimizer.spot_interruption_handling()
```

---

### 7.2 æ··åˆäº‘æ¶æ„

```python
"""
æ··åˆäº‘è®­ç»ƒæ¶æ„
"""

class HybridCloudArchitecture:
    """
    æ··åˆäº‘ï¼ˆOn-premise + Cloudï¼‰
    
    ç­–ç•¥ï¼š
    - æ—¥å¸¸è®­ç»ƒï¼šè‡ªå»ºé›†ç¾¤
    - å³°å€¼éœ€æ±‚ï¼šCloud burst
    - æˆæœ¬ä¼˜åŒ–ï¼šReserved + Spotæ··åˆ
    """
    
    def design_hybrid_architecture(self):
        """
        æ··åˆäº‘æ¶æ„è®¾è®¡
        """
        print("æ··åˆäº‘æ¶æ„:")
        print("="*70)
        print("""
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  On-Premiseé›†ç¾¤ (è‡ªå»º)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ åŸºç¡€å®¹é‡: 64x H100                      â”‚     â”‚
â”‚  â”‚ åˆ©ç”¨ç‡ç›®æ ‡: 80%                         â”‚     â”‚
â”‚  â”‚ ç”¨é€”: æ—¥å¸¸è®­ç»ƒã€å®éªŒ                     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â†“ å³°å€¼æ—¶burståˆ°äº‘ç«¯
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cloud (AWS/GCP/Azure)                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Reservedå®ä¾‹: 32x H100 (3å¹´ï¼Œçœ50%)     â”‚     â”‚
â”‚  â”‚ Spotå®ä¾‹: 0-128x H100 (çœ70%)           â”‚     â”‚
â”‚  â”‚ ç”¨é€”: å¼¹æ€§æ‰©å±•ã€ç´§æ€¥è®­ç»ƒ                 â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        """)
        
        # æˆæœ¬åˆ†æ
        self.calculate_hybrid_cost()
    
    def calculate_hybrid_cost(self):
        """
        æ··åˆäº‘æˆæœ¬è®¡ç®—
        """
        print("\næˆæœ¬å¯¹æ¯”ï¼ˆå¹´åº¦ï¼‰:")
        print("="*70)
        
        # åœºæ™¯ï¼šå¹³å‡64 GPUä½¿ç”¨ï¼Œå³°å€¼128 GPU
        
        # æ–¹æ¡ˆ1: å…¨éƒ¨On-Premise
        on_premise_capex = 250_000 * 16  # 16å°DGX H100
        on_premise_opex = 100_000  # ç”µè´¹+ç»´æŠ¤
        on_premise_total = on_premise_capex + on_premise_opex
        
        print("\næ–¹æ¡ˆ1ï¼šå…¨éƒ¨On-Premise (128 GPU)")
        print(f"  CAPEX (ç¡¬ä»¶): ${on_premise_capex:,}")
        print(f"  OPEX (ç”µè´¹/ç»´æŠ¤): ${on_premise_opex:,}/å¹´")
        print(f"  3å¹´TCO: ${(on_premise_total + on_premise_opex * 2):,}")
        
        # æ–¹æ¡ˆ2: å…¨éƒ¨Cloud (On-Demand)
        hours_per_year = 365 * 24
        cloud_on_demand = 98.32 * 128 * hours_per_year  # 128x H100
        
        print("\næ–¹æ¡ˆ2ï¼šå…¨éƒ¨Cloud On-Demand (128 GPU)")
        print(f"  å¹´åº¦æˆæœ¬: ${cloud_on_demand:,}")
        print(f"  3å¹´TCO: ${cloud_on_demand * 3:,}")
        
        # æ–¹æ¡ˆ3: æ··åˆäº‘
        # - On-Premise: 64 GPU (åŸºç¡€è´Ÿè½½)
        # - Reserved: 32 GPU (70%æ—¶é—´ä½¿ç”¨)
        # - Spot: 32 GPU (å³°å€¼æ—¶ä½¿ç”¨ï¼Œ30%æ—¶é—´)
        
        hybrid_on_premise = 250_000 * 8 + 50_000  # 8å°DGX + è¿ç»´
        hybrid_reserved = 98.32 * 32 * hours_per_year * 0.5  # Reservedçœ50%
        hybrid_spot = 98.32 * 32 * hours_per_year * 0.3 * 0.3  # Spotçœ70%ï¼Œç”¨30%æ—¶é—´
        hybrid_total_annual = hybrid_on_premise + hybrid_reserved + hybrid_spot
        
        print("\næ–¹æ¡ˆ3ï¼šæ··åˆäº‘ (64 on-premise + 32 reserved + 32 spot)")
        print(f"  On-Premise: ${hybrid_on_premise:,}/å¹´")
        print(f"  Reserved: ${hybrid_reserved:,}/å¹´")
        print(f"  Spot: ${hybrid_spot:,}/å¹´")
        print(f"  å¹´åº¦æˆæœ¬: ${hybrid_total_annual:,}")
        print(f"  3å¹´TCO: ${hybrid_total_annual * 3:,}")
        
        print("\nğŸ“Š æˆæœ¬å¯¹æ¯”æ€»ç»“:")
        print(f"  å…¨On-Premise 3å¹´: ${(on_premise_total + on_premise_opex * 2):,}")
        print(f"  å…¨Cloud 3å¹´:      ${cloud_on_demand * 3:,}")
        print(f"  æ··åˆäº‘ 3å¹´:       ${hybrid_total_annual * 3:,}")
        print(f"\nğŸ”¥ æ··åˆäº‘èŠ‚çœ: {(1 - hybrid_total_annual * 3 / (cloud_on_demand * 3)) * 100:.0f}%")

hybrid = HybridCloudArchitecture()
hybrid.design_hybrid_architecture()
```

---

<a name="monitoring-system"></a>
## ğŸ“Š 8. ç›‘æ§ä½“ç³»ï¼šDCGM + Prometheus + Grafana

### 8.1 DCGM (Data Center GPU Manager)

```bash
# ============================================
# DCGMå®‰è£…ä¸é…ç½®
# ============================================

# 1. å®‰è£…DCGM (æ‰€æœ‰GPUèŠ‚ç‚¹)
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt-get update
sudo apt-get install -y datacenter-gpu-manager

# 2. å¯åŠ¨DCGMæœåŠ¡
sudo systemctl start nvidia-dcgm
sudo systemctl enable nvidia-dcgm

# 3. éªŒè¯DCGM
dcgmi discovery -l

# è¾“å‡ºï¼š
# 8 GPUs found.
# +--------+----------------------------------------------------------------------+
# | GPU ID | Device Information                                                   |
# +--------+----------------------------------------------------------------------+
# | 0      | Name: NVIDIA H100 80GB HBM3                                          |
# | 1      | Name: NVIDIA H100 80GB HBM3                                          |
# ...

# 4. æŸ¥çœ‹GPUæŒ‡æ ‡
dcgmi dmon -e 100,101,102,103,104  # æ¸©åº¦ã€åŠŸç‡ã€SMåˆ©ç”¨ç‡ã€æ˜¾å­˜

# ============================================
# DCGM Exporter for Prometheus
# ============================================

# ä½¿ç”¨Helmå®‰è£…DCGM Exporter
helm repo add gpu-helm-charts https://nvidia.github.io/dcgm-exporter/helm-charts
helm repo update

helm install dcgm-exporter gpu-helm-charts/dcgm-exporter \
    --namespace gpu-monitoring \
    --create-namespace

# éªŒè¯
kubectl get pods -n gpu-monitoring

# DCGM Exporterä¼šæš´éœ²metricsåœ¨ :9400/metrics
```

---

### 8.2 å®Œæ•´ç›‘æ§æ ˆéƒ¨ç½²

```yaml
# ============================================
# Prometheusé…ç½®ï¼ˆç›‘æ§GPUï¼‰
# ============================================

# prometheus-values.yaml (Helmé…ç½®)
prometheus:
  prometheusSpec:
    # Scrape DCGM Exporter
    additionalScrapeConfigs:
      - job_name: 'dcgm-exporter'
        kubernetes_sd_configs:
          - role: pod
            namespaces:
              names:
                - gpu-monitoring
        relabel_configs:
          - source_labels: [__meta_kubernetes_pod_label_app]
            action: keep
            regex: dcgm-exporter
    
    # å­˜å‚¨é…ç½®
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: fast-ssd
          resources:
            requests:
              storage: 100Gi
    
    # èµ„æºé…ç½®
    resources:
      requests:
        cpu: 2000m
        memory: 8Gi
      limits:
        cpu: 4000m
        memory: 16Gi

# å®‰è£…Prometheus Stack
helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
    -f prometheus-values.yaml \
    -n monitoring \
    --create-namespace
```

---

### 8.3 Grafana Dashboardé…ç½®

```python
"""
Grafana GPUç›‘æ§Dashboard
"""

def create_gpu_monitoring_dashboard():
    """
    åˆ›å»ºGPUç›‘æ§Dashboard
    """
    panels = [
        {
            'title': 'GPUåˆ©ç”¨ç‡',
            'query': 'DCGM_FI_DEV_GPU_UTIL',
            'description': 'ç›®æ ‡ï¼š>80%',
            'alert_threshold': 50  # <50%å‘Šè­¦ï¼ˆåˆ©ç”¨ç‡ä½ï¼‰
        },
        {
            'title': 'GPUæ˜¾å­˜ä½¿ç”¨',
            'query': 'DCGM_FI_DEV_FB_USED / DCGM_FI_DEV_FB_TOTAL * 100',
            'description': 'æ˜¾å­˜ä½¿ç”¨ç™¾åˆ†æ¯”',
            'alert_threshold': 95  # >95%å‘Šè­¦ï¼ˆæ¥è¿‘OOMï¼‰
        },
        {
            'title': 'GPUæ¸©åº¦',
            'query': 'DCGM_FI_DEV_GPU_TEMP',
            'description': 'GPUæ¸©åº¦ï¼ˆâ„ƒï¼‰',
            'alert_threshold': 85  # >85â„ƒå‘Šè­¦
        },
        {
            'title': 'GPUåŠŸç‡',
            'query': 'DCGM_FI_DEV_POWER_USAGE',
            'description': 'å½“å‰åŠŸè€—ï¼ˆWï¼‰',
            'alert_threshold': 700  # H100æœ€å¤§700W
        },
        {
            'title': 'NVLinkå¸¦å®½',
            'query': 'DCGM_FI_PROF_NVLINK_TX_BYTES + DCGM_FI_PROF_NVLINK_RX_BYTES',
            'description': 'NVLinkä¼ è¾“å¸¦å®½ï¼ˆGB/sï¼‰',
            'alert_threshold': None
        },
        {
            'title': 'PCIeå¸¦å®½',
            'query': 'DCGM_FI_PROF_PCIE_TX_BYTES + DCGM_FI_PROF_PCIE_RX_BYTES',
            'description': 'PCIeä¼ è¾“å¸¦å®½ï¼ˆGB/sï¼‰',
            'alert_threshold': None
        },
        {
            'title': 'Tensor Coreåˆ©ç”¨ç‡',
            'query': 'DCGM_FI_PROF_PIPE_TENSOR_ACTIVE',
            'description': 'Tensor Coreæ´»è·ƒç™¾åˆ†æ¯”',
            'alert_threshold': 50
        },
        {
            'title': 'ECCé”™è¯¯',
            'query': 'DCGM_FI_DEV_ECC_DBE_VOL_TOTAL',
            'description': 'ECCåŒä½é”™è¯¯ï¼ˆä¸¥é‡ï¼‰',
            'alert_threshold': 0  # ä»»ä½•é”™è¯¯éƒ½å‘Šè­¦
        }
    ]
    
    print("GPUç›‘æ§Dashboardé¢æ¿:")
    print("="*70)
    for i, panel in enumerate(panels, 1):
        print(f"\n{i}. {panel['title']}")
        print(f"   PromQL: {panel['query']}")
        print(f"   è¯´æ˜: {panel['description']}")
        if panel['alert_threshold'] is not None:
            print(f"   å‘Šè­¦é˜ˆå€¼: {panel['alert_threshold']}")
    
    return panels

# åˆ›å»ºDashboard
panels = create_gpu_monitoring_dashboard()

# Grafanaè‡ªåŠ¨ç”Ÿæˆçš„Dashboard ID
grafana_dashboards = {
    'NVIDIA DCGM Exporter Dashboard': 12219,
    'NVIDIA GPU Monitoring': 15117,
}

print("\n\næ¨èGrafana Dashboard (å¯å¯¼å…¥):")
for name, dashboard_id in grafana_dashboards.items():
    print(f"  {name}: https://grafana.com/grafana/dashboards/{dashboard_id}")
```

---

<a name="fault-diagnosis"></a>
## ğŸ”§ 9. æ•…éšœè¯Šæ–­ä¸æ¢å¤

### 9.1 å¸¸è§GPUé›†ç¾¤æ•…éšœ

```python
"""
GPUé›†ç¾¤æ•…éšœè¯Šæ–­æ‰‹å†Œ
"""

class GPUClusterTroubleshooting:
    """
    GPUé›†ç¾¤æ•…éšœè¯Šæ–­
    """
    
    def diagnose_gpu_not_detected(self):
        """
        æ•…éšœ1ï¼šGPUæ£€æµ‹ä¸åˆ°
        """
        print("âŒ æ•…éšœï¼škubectlæ— æ³•çœ‹åˆ°GPUèµ„æº")
        print("="*70)
        
        diagnostics = [
            {
                'check': '1. æ£€æŸ¥NVIDIAé©±åŠ¨',
                'command': 'nvidia-smi',
                'expected': 'æ˜¾ç¤ºGPUåˆ—è¡¨',
                'fix': 'sudo apt-get install nvidia-driver-535'
            },
            {
                'check': '2. æ£€æŸ¥GPU Operator Pod',
                'command': 'kubectl get pods -n gpu-operator',
                'expected': 'æ‰€æœ‰Pod Running',
                'fix': 'kubectl logs -n gpu-operator <pod-name>'
            },
            {
                'check': '3. æ£€æŸ¥Device Plugin',
                'command': 'kubectl get ds -n gpu-operator nvidia-device-plugin-daemonset',
                'expected': 'DaemonSet Ready',
                'fix': 'æ£€æŸ¥èŠ‚ç‚¹labelå’Œtoleration'
            },
            {
                'check': '4. æ£€æŸ¥èŠ‚ç‚¹GPUèµ„æº',
                'command': 'kubectl describe node <node-name> | grep nvidia.com/gpu',
                'expected': 'Capacity: nvidia.com/gpu: 8',
                'fix': 'é‡å¯GPU Operator: helm upgrade ...'
            }
        ]
        
        for diag in diagnostics:
            print(f"\n{diag['check']}")
            print(f"  å‘½ä»¤: {diag['command']}")
            print(f"  æœŸæœ›: {diag['expected']}")
            print(f"  ä¿®å¤: {diag['fix']}")
    
    def diagnose_nccl_hang(self):
        """
        æ•…éšœ2ï¼šNCCLé€šä¿¡æŒ‚èµ·
        """
        print("\n\nâŒ æ•…éšœï¼šè®­ç»ƒå¡æ­»ï¼ˆNCCL hangï¼‰")
        print("="*70)
        
        diagnostics = [
            {
                'symptom': 'æ‰€æœ‰è¿›ç¨‹å¡åœ¨AllReduce',
                'possible_causes': [
                    'ç½‘ç»œé…ç½®é”™è¯¯',
                    'InfiniBandæœªå¯ç”¨',
                    'é˜²ç«å¢™é˜»æ­¢é€šä¿¡',
                    'ç½‘å¡æ•…éšœ'
                ],
                'diagnosis_steps': [
                    '1. æ£€æŸ¥NCCLæ—¥å¿—: export NCCL_DEBUG=INFO',
                    '2. æµ‹è¯•ç½‘ç»œ: nccl-tests/build/all_reduce_perf -b 8 -e 128M -f 2 -g 8',
                    '3. æ£€æŸ¥IBçŠ¶æ€: ibstat',
                    '4. æµ‹è¯•èŠ‚ç‚¹é—´é€šä¿¡: ib_write_bw <remote-ip>'
                ],
                'fixes': [
                    'export NCCL_IB_DISABLE=0  # å¯ç”¨IB',
                    'export NCCL_SOCKET_IFNAME=ib0  # æŒ‡å®šIBç½‘å¡',
                    'export NCCL_IB_HCA=mlx5  # æŒ‡å®šIBé€‚é…å™¨',
                    'æ£€æŸ¥/etc/hostsé…ç½®ä¸»æœºå'
                ]
            }
        ]
        
        for diag in diagnostics:
            print(f"\nç—‡çŠ¶: {diag['symptom']}")
            print(f"\nå¯èƒ½åŸå› :")
            for cause in diag['possible_causes']:
                print(f"  - {cause}")
            print(f"\nè¯Šæ–­æ­¥éª¤:")
            for step in diag['diagnosis_steps']:
                print(f"  {step}")
            print(f"\nä¿®å¤æ–¹æ³•:")
            for fix in diag['fixes']:
                print(f"  {fix}")
    
    def diagnose_oom(self):
        """
        æ•…éšœ3ï¼šGPU OOM
        """
        print("\n\nâŒ æ•…éšœï¼šGPU Out of Memory")
        print("="*70)
        
        print("""
è¯Šæ–­æ­¥éª¤ï¼š

1. æ£€æŸ¥æ˜¾å­˜å ç”¨
   nvidia-smi
   
   åˆ†æï¼š
   - æ¨¡å‹å‚æ•°å ç”¨
   - æ¢¯åº¦å ç”¨
   - ä¼˜åŒ–å™¨çŠ¶æ€å ç”¨
   - æ¿€æ´»å€¼å ç”¨

2. è®¡ç®—ç†è®ºæ˜¾å­˜éœ€æ±‚
   total_memory = model_params * (2 + 2 + 8 + activation_multiplier)
   - 2 bytes: FP16å‚æ•°
   - 2 bytes: FP16æ¢¯åº¦
   - 8 bytes: Adamä¼˜åŒ–å™¨ï¼ˆ2ä¸ªmoment + FP32 masterï¼‰
   - activation_multiplier: é€šå¸¸10-20å€å‚æ•°é‡

3. è§£å†³æ–¹æ¡ˆï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
   âœ… å‡å°batch size
   âœ… å¯ç”¨æ¢¯åº¦ç´¯ç§¯
   âœ… å¯ç”¨gradient checkpointing
   âœ… ä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆFP16/BF16ï¼‰
   âœ… ä½¿ç”¨FSDP/DeepSpeed ZeRO
   âœ… å‡å°åºåˆ—é•¿åº¦
        """)

troubleshooter = GPUClusterTroubleshooting()
troubleshooter.diagnose_gpu_not_detected()
troubleshooter.diagnose_nccl_hang()
troubleshooter.diagnose_oom()
```

---

<a name="capacity-planning"></a>
## ğŸ“ 10. å®¹é‡è§„åˆ’ä¸æ‰©å±•

### 10.1 å®¹é‡è§„åˆ’è®¡ç®—å™¨

```python
"""
GPUé›†ç¾¤å®¹é‡è§„åˆ’
"""

class GPUCapacityPlanner:
    """
    GPUé›†ç¾¤å®¹é‡è§„åˆ’å·¥å…·
    """
    
    def __init__(self):
        # GPUè§„æ ¼
        self.gpu_specs = {
            'H100': {'memory_gb': 80, 'price_per_hour': 5.00},
            'A100-80GB': {'memory_gb': 80, 'price_per_hour': 3.50},
            'A100-40GB': {'memory_gb': 40, 'price_per_hour': 2.50},
        }
    
    def estimate_training_time(
        self,
        model_params_b=70,
        dataset_tokens_b=1000,
        num_gpus=64,
        gpu_type='H100'
    ):
        """
        ä¼°ç®—è®­ç»ƒæ—¶é—´
        
        åŸºäºDeepSeek-V3ç»éªŒï¼š
        - 671Bæ¨¡å‹ï¼Œ14.8T tokens â†’ 2788K GPU-hours (H800)
        """
        # ç®€åŒ–ä¼°ç®—å…¬å¼ï¼ˆç»éªŒï¼‰
        # GPU-hours â‰ˆ model_params_B * dataset_tokens_B * 0.004
        
        gpu_hours = model_params_b * dataset_tokens_b * 0.004
        
        # è€ƒè™‘æ•ˆç‡æŸå¤±ï¼ˆé€šä¿¡ã€IOç­‰ï¼‰
        efficiency = 0.85  # 85%æ•ˆç‡
        actual_gpu_hours = gpu_hours / efficiency
        
        # è®¡ç®—wallclockæ—¶é—´
        wallclock_hours = actual_gpu_hours / num_gpus
        wallclock_days = wallclock_hours / 24
        
        # æˆæœ¬
        cost_per_hour = self.gpu_specs[gpu_type]['price_per_hour']
        total_cost = actual_gpu_hours * cost_per_hour
        
        print(f"è®­ç»ƒæ—¶é—´ä¼°ç®—:")
        print("="*70)
        print(f"æ¨¡å‹è§„æ¨¡: {model_params_b}Bå‚æ•°")
        print(f"æ•°æ®è§„æ¨¡: {dataset_tokens_b}B tokens")
        print(f"GPUé…ç½®: {num_gpus}x {gpu_type}")
        print(f"\nä¼°ç®—ç»“æœ:")
        print(f"  GPU-hours: {actual_gpu_hours:,.0f}")
        print(f"  å®é™…è®­ç»ƒæ—¶é—´: {wallclock_days:.1f} å¤©")
        print(f"  æ€»æˆæœ¬: ${total_cost:,.0f}")
        print(f"  æ¯å¤©æˆæœ¬: ${total_cost/wallclock_days:,.0f}")
        
        return wallclock_days, total_cost
    
    def plan_cluster_size(
        self,
        monthly_training_jobs=10,
        avg_model_size_b=13,
        avg_dataset_b=100,
        target_turnaround_days=3
    ):
        """
        è§„åˆ’é›†ç¾¤è§„æ¨¡
        """
        print(f"\né›†ç¾¤è§„æ¨¡è§„åˆ’:")
        print("="*70)
        print(f"éœ€æ±‚:")
        print(f"  æ¯æœˆè®­ç»ƒä½œä¸š: {monthly_training_jobs}")
        print(f"  å¹³å‡æ¨¡å‹è§„æ¨¡: {avg_model_size_b}B")
        print(f"  å¹³å‡æ•°æ®è§„æ¨¡: {avg_dataset_b}B tokens")
        print(f"  ç›®æ ‡å®Œæˆæ—¶é—´: {target_turnaround_days}å¤©")
        
        # å•ä¸ªä½œä¸šGPU-hours
        gpu_hours_per_job = avg_model_size_b * avg_dataset_b * 0.004 / 0.85
        
        # å•ä¸ªä½œä¸šæ‰€éœ€GPUæ•°ï¼ˆåœ¨target_turnaround_dayså†…å®Œæˆï¼‰
        gpus_per_job = gpu_hours_per_job / (target_turnaround_days * 24)
        
        # è€ƒè™‘å¹¶å‘ï¼ˆå‡è®¾å¹³å‡3ä¸ªä½œä¸šåŒæ—¶è¿è¡Œï¼‰
        concurrent_jobs = 3
        total_gpus_needed = gpus_per_job * concurrent_jobs
        
        # å‘ä¸Šå–æ•´åˆ°8çš„å€æ•°ï¼ˆ8å¡æœåŠ¡å™¨ï¼‰
        num_nodes = int(np.ceil(total_gpus_needed / 8))
        total_gpus = num_nodes * 8
        
        print(f"\næ¨èé…ç½®:")
        print(f"  å•ä½œä¸šGPU-hours: {gpu_hours_per_job:,.0f}")
        print(f"  å•ä½œä¸šæ‰€éœ€GPU: {gpus_per_job:.0f}")
        print(f"  å¹¶å‘ä½œä¸šæ•°: {concurrent_jobs}")
        print(f"  æ€»GPUéœ€æ±‚: {total_gpus_needed:.0f}")
        print(f"  æ¨èèŠ‚ç‚¹æ•°: {num_nodes} (8å¡/èŠ‚ç‚¹)")
        print(f"  æ€»GPUæ•°: {total_gpus}")
        
        # æˆæœ¬ä¼°ç®—
        gpu_type = 'H100'
        monthly_cost = (
            total_gpus * 
            self.gpu_specs[gpu_type]['price_per_hour'] * 
            24 * 30
        )
        
        print(f"\næˆæœ¬ä¼°ç®— ({gpu_type}):")
        print(f"  æœˆåº¦æˆæœ¬: ${monthly_cost:,.0f}")
        print(f"  å¹´åº¦æˆæœ¬: ${monthly_cost * 12:,.0f}")

planner = GPUCapacityPlanner()

# ç¤ºä¾‹1ï¼š70Bæ¨¡å‹è®­ç»ƒ
planner.estimate_training_time(
    model_params_b=70,
    dataset_tokens_b=1000,
    num_gpus=64,
    gpu_type='H100'
)

# ç¤ºä¾‹2ï¼šé›†ç¾¤è§„æ¨¡è§„åˆ’
planner.plan_cluster_size(
    monthly_training_jobs=10,
    avg_model_size_b=13,
    avg_dataset_b=100,
    target_turnaround_days=3
)
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

### GPUç®¡ç†

1. **NVIDIA GPU Operator**  
   [GPU Operator Documentation](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/latest/)  
   K8s GPUç®¡ç†ï¼ˆ2025 v25.10.1ï¼‰

2. **NVIDIA DCGM**  
   [DCGM Exporter](https://github.com/NVIDIA/dcgm-exporter)  
   GPUç›‘æ§å·¥å…·

### ä½œä¸šè°ƒåº¦

3. **SLURM**  
   [SLURM Documentation](https://slurm.schedmd.com/documentation.html)  
   ä½œä¸šè°ƒåº¦ç³»ç»Ÿï¼ˆv25.11ï¼‰

4. **Kubeflow PyTorchJob**  
   [PyTorchJob Guide](https://www.kubeflow.org/docs/components/training/pytorch/)  
   K8såˆ†å¸ƒå¼è®­ç»ƒ

### é«˜æ€§èƒ½å­˜å‚¨

5. **Lustre**  
   - [AWS FSx for Lustre](https://aws.amazon.com/fsx/lustre/)  
   - [Google Managed Lustre](https://cloud.google.com/managed-lustre/docs/overview)  
   PBçº§é«˜æ€§èƒ½å­˜å‚¨

6. **Lustre vs GPFS**  
   [Lustre vs GPFS Comparison](https://www.baculasystems.com/blog/lustre-vs-gpfs/)  
   ä¸¤å¤§HPCæ–‡ä»¶ç³»ç»Ÿå¯¹æ¯”

### ç½‘ç»œä¼˜åŒ–

7. **RDMA & InfiniBand**  
   [NVIDIA InfiniBand Solutions](https://docs.nvidia.com/networking/)  
   é«˜é€Ÿç½‘ç»œé…ç½®

8. **GPUDirect RDMA**  
   [GPUDirect RDMA Benchmark](https://docs.oracle.com/en/learn/gpudirect-rdma-ib-write-bw/)  
   GPUç›´æ¥RDMAé€šä¿¡

### æˆæœ¬ä¼˜åŒ–

9. **AWS Spot Instances**  
   [Spot Best Practices](https://docs.aws.amazon.com/whitepapers/latest/cost-optimization-leveraging-ec2-spot-instances/spot-best-practices.html)  
   Spotå®ä¾‹æœ€ä½³å®è·µ

### ç›‘æ§å‘Šè­¦

10. **Prometheus & Grafana**  
    [Grafana ML Monitoring](https://grafana.com/blog/monitoring-machine-learning-models-in-production-with-grafana-and-clearml/)  
    MLç›‘æ§å®è·µ

---

## ğŸ¯ æ€»ç»“

### å…³é”®è¦ç‚¹å›é¡¾

1. **GPUé€‰å‹**ï¼šH100é¦–é€‰å¤§è§„æ¨¡è®­ç»ƒï¼ŒA100æ€§ä»·æ¯”é«˜ï¼ŒRTX 4090é€‚åˆç ”ç©¶
2. **ç¼–æ’é€‰æ‹©**ï¼šK8sï¼ˆäº‘åŸç”Ÿï¼‰+ SLURMï¼ˆHPCæˆç†Ÿï¼‰æ··åˆä½¿ç”¨
3. **å­˜å‚¨ç³»ç»Ÿ**ï¼šLustreæ˜¯PBçº§è®­ç»ƒæ•°æ®çš„æ ‡å‡†æ–¹æ¡ˆ
4. **ç½‘ç»œä¼˜åŒ–**ï¼šInfiniBand + RDMAæ˜¯å¤§è§„æ¨¡è®­ç»ƒå¿…å¤‡
5. **æˆæœ¬ä¼˜åŒ–**ï¼šæ··åˆäº‘ + Spotå®ä¾‹å¯èŠ‚çœ50-70%
6. **ç›‘æ§ä½“ç³»**ï¼šDCGM + Prometheus + Grafanaä¸‰ä»¶å¥—

### åŸºç¡€è®¾æ–½è§„æ¨¡å‚è€ƒ

| æ¨¡å‹è§„æ¨¡ | GPUæ•°é‡ | ç½‘ç»œ | å­˜å‚¨ | æˆæœ¬/7å¤©è®­ç»ƒ |
|---------|---------|------|------|-------------|
| 7B | 8 | Ethernet | NVMe | ~$3K |
| 13B-30B | 32 | InfiniBand | Lustre | ~$30K |
| 70B | 64 | InfiniBand | Lustre | ~$150K |
| 175B+ | 512+ | InfiniBand | Lustre | ~$1.5M |

### ä¼ ç»Ÿç¨‹åºå‘˜çš„ä¼˜åŠ¿

- âœ… **ç³»ç»Ÿæ¶æ„èƒ½åŠ›**ï¼šåˆ†å¸ƒå¼ç³»ç»Ÿã€ç½‘ç»œã€å­˜å‚¨æ˜¯å·²æœ‰æŠ€èƒ½
- âœ… **è¿ç»´ç»éªŒ**ï¼šç›‘æ§ã€å‘Šè­¦ã€æ•…éšœè¯Šæ–­ç›´æ¥è¿ç§»
- âœ… **æˆæœ¬æ„è¯†**ï¼šèµ„æºä¼˜åŒ–ã€å®¹é‡è§„åˆ’æ˜¯å·¥ç¨‹å¸ˆåŸºæœ¬åŠŸ

### ä¸‹ä¸€æ­¥å­¦ä¹ 

- ğŸ”— **ä¸‹ä¸€ç¯‡**ï¼š[13 - ç”Ÿäº§åŒ–éƒ¨ç½²æŒ‡å—ï¼šä»è®­ç»ƒåˆ°æœåŠ¡çš„å®Œæ•´æµç¨‹](./13-production-deployment.md)
- ğŸ’» **åŠ¨æ‰‹å®è·µ**ï¼šæ­å»ºæœ¬åœ°K8s + GPU Operatorç¯å¢ƒ
- ğŸ“Š **å®æˆ˜é¡¹ç›®**ï¼šé…ç½®DCGM + Grafanaç›‘æ§è‡ªå·±çš„GPU

---

> ğŸ’¡ **ç’‡ç‘çš„å°è´´å£«**ï¼šè®­ç»ƒåŸºç¡€è®¾æ–½å°±åƒæ­å»ºæ•°æ®ä¸­å¿ƒâ€”â€”GPUæ˜¯CPUï¼ŒInfiniBandæ˜¯ç½‘ç»œï¼ŒLustreæ˜¯åˆ†å¸ƒå¼å­˜å‚¨ã€‚ä¼ ç»Ÿç¨‹åºå‘˜çš„ç³»ç»Ÿæ¶æ„èƒ½åŠ›åœ¨è¿™é‡Œæ˜¯æ ¸å¿ƒä¼˜åŠ¿ï¼ç¡¬ä»¶å’Œè½¯ä»¶çš„ååŒä¼˜åŒ–ï¼Œæ‰èƒ½å‘æŒ¥GPUçš„æœ€å¤§ä»·å€¼~ âœ¨
>
> é“å‹ç°åœ¨å¯¹è®­ç»ƒåŸºç¡€è®¾æ–½æœ‰æ„Ÿè§‰äº†å—ï¼Ÿä¸‹ä¸€ç¯‡æˆ‘ä»¬èŠç”Ÿäº§åŒ–éƒ¨ç½²ï¼Œæ•™ä½ å¦‚ä½•æŠŠè®­ç»ƒå¥½çš„æ¨¡å‹ç¨³å®šé«˜æ•ˆåœ°servingèµ·æ¥ï¼ğŸš€